{
  "cells": [
    {
      "id": "4f4a224f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "%pip install -q spd_learn moabb braindecode scikit-learn matplotlib\n\n# For GPU support (recommended for faster training)\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# fNIRS Classification with SPD Learn\n\nThis tutorial demonstrates how to classify functional Near-Infrared\nSpectroscopy (fNIRS) data using SPD Learn's Riemannian methods. We use\nthe real fNIRS motor dataset from MNE-NIRS to compare deep learning\napproaches (SPDNet, TSMNet) with pyRiemann baselines.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nfNIRS is a non-invasive neuroimaging technique that measures brain\nactivity by detecting changes in blood oxygenation. It provides:\n\n- **HbO (oxygenated hemoglobin)**: Increases with neural activity\n- **HbR (deoxygenated hemoglobin)**: Decreases with neural activity\n\nfNIRS signals can be represented as covariance matrices, making them\nsuitable for Riemannian geometry-based classification methods.\n\nThis tutorial shows how to:\n\n1. Load real fNIRS data from the MNE-NIRS motor group dataset\n2. Preprocess and epoch the data\n3. Compute covariance matrices from fNIRS signals\n4. Apply SPD Learn models (SPDNet, TSMNet)\n5. Compare with pyRiemann baselines (MDM, Tangent Space)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport warnings\n\nfrom pathlib import Path\n\nimport matplotlib\n\n\nmatplotlib.use(\"Agg\")  # Non-interactive backend - no popup windows\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder\n\n\nwarnings.filterwarnings(\"ignore\")\n\n# Set random seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nimport mne\n\nfrom mne_nirs.datasets import fnirs_motor_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Real fNIRS Data\n\nWe use the fNIRS motor group dataset from MNE-NIRS, which contains\ndata from a finger tapping experiment. Subjects perform left and\nright hand finger tapping tasks.\n\nWe load more subjects (1-5) to have enough data for deep learning.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading real fNIRS data from MNE-NIRS...\")\n\n# Get data path (convert to Path object for path operations)\ndata_path = Path(fnirs_motor_group.data_path())\n\n# Load data for multiple subjects\nall_epochs = []\nall_labels = []\n\n# Use subjects 1-2 for faster documentation build\nsubjects = [1, 2]  # Reduced from [1, 2, 3, 4, 5] for speed\n\nfor subj in subjects:\n    # Construct file path for this subject\n    raw_path = (\n        data_path / f\"sub-0{subj}\" / \"nirs\" / f\"sub-0{subj}_task-tapping_nirs.snirf\"\n    )\n\n    if not raw_path.exists():\n        print(f\"Subject {subj} data not found, skipping...\")\n        continue\n\n    print(f\"  Loading subject {subj}...\")\n\n    # Load raw data\n    raw = mne.io.read_raw_snirf(raw_path, preload=True, verbose=False)\n\n    # Convert to optical density\n    raw_od = mne.preprocessing.nirs.optical_density(raw)\n\n    # Convert to hemoglobin concentrations\n    raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)\n\n    # Filter to remove noise\n    raw_haemo = raw_haemo.filter(0.01, 0.5, verbose=False)\n\n    # Get events from annotations\n    events, event_id = mne.events_from_annotations(raw_haemo, verbose=False)\n\n    # Keep only tapping events (usually '1' = left, '2' = right)\n    # Filter for control vs tapping if available\n    if \"1.0\" in event_id and \"2.0\" in event_id:\n        event_id_filt = {\"left\": event_id[\"1.0\"], \"right\": event_id[\"2.0\"]}\n    elif \"Tapping/Left\" in event_id and \"Tapping/Right\" in event_id:\n        event_id_filt = {\n            \"left\": event_id[\"Tapping/Left\"],\n            \"right\": event_id[\"Tapping/Right\"],\n        }\n    else:\n        # Use first two event types\n        event_names = list(event_id.keys())[:2]\n        event_id_filt = {name: event_id[name] for name in event_names}\n\n    # Create epochs\n    epochs = mne.Epochs(\n        raw_haemo,\n        events,\n        event_id=event_id_filt,\n        tmin=-2,\n        tmax=15,\n        baseline=(None, 0),\n        preload=True,\n        verbose=False,\n    )\n\n    # Get data and labels\n    X_subj = epochs.get_data()  # (n_epochs, n_channels, n_times)\n    y_subj = epochs.events[:, -1]\n\n    all_epochs.append(X_subj)\n    all_labels.append(y_subj)\n\n# Concatenate all subjects\nX = np.concatenate(all_epochs, axis=0)\ny = np.concatenate(all_labels, axis=0)\n\n# Relabel to 0, 1\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nn_samples, n_channels, n_times = X.shape\nsfreq = raw_haemo.info[\"sfreq\"]\n\nprint(f\"\\nLoaded {n_samples} trials from {len(subjects)} subjects\")\nprint(f\"Channels: {n_channels}, Time points: {n_times}\")\nprint(f\"Sampling rate: {sfreq:.1f} Hz\")\nprint(f\"Class distribution: {np.bincount(y)}\")\n\nprint(f\"\\nData shape: {X.shape}\")\nprint(f\"Labels: {np.unique(y, return_counts=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing Covariance Matrices\n\nWe compute covariance matrices from the fNIRS signals using\nshrinkage estimators for better conditioning.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyriemann.estimation import Covariances\n\n\nprint(\"\\nComputing covariance matrices...\")\n\n# Use Ledoit-Wolf shrinkage estimator\ncov_estimator = Covariances(estimator=\"lwf\")\nX_cov = cov_estimator.fit_transform(X)\n\nprint(f\"Covariance matrices shape: {X_cov.shape}\")\n\n# Analyze eigenvalue spectrum\neigvals = np.linalg.eigvalsh(X_cov)\nprint(\"\\nEigenvalue statistics:\")\nprint(f\"  Min eigenvalue: {eigvals.min():.6f}\")\nprint(f\"  Max eigenvalue: {eigvals.max():.6f}\")\nprint(\n    f\"  Mean condition number: {(eigvals.max(axis=1) / eigvals.min(axis=1)).mean():.2f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing fNIRS Signals and Covariances\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot sample signals for each class\nfor class_idx, class_name in enumerate([\"Class 0\", \"Class 1\"]):\n    ax = axes[0, class_idx]\n    class_mask = y == class_idx\n    sample_idx = np.where(class_mask)[0][0]\n\n    # Plot first 5 channels\n    for ch in range(min(5, X.shape[1])):\n        ax.plot(X[sample_idx, ch, :], alpha=0.7, label=f\"Ch {ch + 1}\")\n\n    ax.set_xlabel(\"Time samples\")\n    ax.set_ylabel(\"Signal amplitude\")\n    ax.set_title(f\"{class_name} - Sample Trial\")\n    ax.legend(loc=\"upper right\", fontsize=8)\n    ax.grid(True, alpha=0.3)\n\n# Plot mean covariance matrices\nfor class_idx, class_name in enumerate([\"Class 0\", \"Class 1\"]):\n    ax = axes[1, class_idx]\n    class_mask = y == class_idx\n    mean_cov = X_cov[class_mask].mean(axis=0)\n\n    im = ax.imshow(mean_cov, cmap=\"RdBu_r\", aspect=\"auto\")\n    ax.set_title(f\"{class_name} - Mean Covariance\")\n    ax.set_xlabel(\"Channel\")\n    ax.set_ylabel(\"Channel\")\n    plt.colorbar(im, ax=ax, shrink=0.8)\n\nplt.suptitle(\"fNIRS Data Visualization\", fontweight=\"bold\", fontsize=14)\nplt.tight_layout()\nplt.savefig(\"fnirs_plot.png\", dpi=100, bbox_inches=\"tight\")\nplt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## pyRiemann Baselines\n\nWe evaluate classical Riemannian methods as baselines:\n\n- **MDM**: Minimum Distance to Mean classifier\n- **TS + LDA**: Tangent Space projection + LDA\n- **TS + LR**: Tangent Space projection + Logistic Regression\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyriemann.classification import MDM\nfrom pyriemann.tangentspace import TangentSpace\n\n\nprint(\"\\nEvaluating pyRiemann baselines...\")\nprint(\"-\" * 50)\n\n# Split data\nX_cov_train, X_cov_test, X_train, X_test, y_train, y_test = train_test_split(\n    X_cov, X, y, test_size=0.3, random_state=SEED, stratify=y\n)\n\nresults = {}\n\n# MDM classifier\nmdm = MDM(metric=\"riemann\")\nmdm.fit(X_cov_train, y_train)\ny_pred_mdm = mdm.predict(X_cov_test)\nacc_mdm = accuracy_score(y_test, y_pred_mdm)\nresults[\"MDM\"] = acc_mdm\nprint(f\"MDM: {acc_mdm * 100:.2f}%\")\n\n# Tangent Space + LDA\nts_lda = make_pipeline(TangentSpace(metric=\"riemann\"), LinearDiscriminantAnalysis())\nts_lda.fit(X_cov_train, y_train)\ny_pred_ts_lda = ts_lda.predict(X_cov_test)\nacc_ts_lda = accuracy_score(y_test, y_pred_ts_lda)\nresults[\"TS + LDA\"] = acc_ts_lda\nprint(f\"TS + LDA: {acc_ts_lda * 100:.2f}%\")\n\n# Tangent Space + Logistic Regression\nts_lr = make_pipeline(\n    TangentSpace(metric=\"riemann\"), LogisticRegression(max_iter=1000, random_state=SEED)\n)\nts_lr.fit(X_cov_train, y_train)\ny_pred_ts_lr = ts_lr.predict(X_cov_test)\nacc_ts_lr = accuracy_score(y_test, y_pred_ts_lr)\nresults[\"TS + LR\"] = acc_ts_lr\nprint(f\"TS + LR: {acc_ts_lr * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Channel Selection for Deep Learning\n\nfNIRS recordings often have many channels (56 in this case), leading to\nhigh-dimensional covariance matrices. Channel selection helps by:\n\n- Reducing dimensionality and overfitting risk\n- Focusing on the most discriminative channels\n- Improving condition numbers of covariance matrices\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_classif\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Performing Channel Selection\")\nprint(\"=\" * 60)\n\n# Compute discriminative power of each channel using F-score\n# Flatten time series to compute per-channel statistics\nX_flat_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1).mean(axis=2)\nf_scores, _ = f_classif(X_flat_train, y_train)\n\n# Select top channels based on F-score\nn_select = min(20, n_channels // 2)  # Select top 20 or half of channels\ntop_channels = np.argsort(f_scores)[::-1][:n_select]\nprint(f\"Selected {n_select} most discriminative channels from {n_channels}\")\nprint(f\"Top channel indices: {top_channels[:10]}...\")  # Show first 10\n\n# Apply channel selection to data\nX_train_sel = X_train[:, top_channels, :]\nX_test_sel = X_test[:, top_channels, :]\n\n# Normalize time series data (important for small-scale data like fNIRS)\n# Normalize per-sample: (X - mean) / std\nfor i in range(X_train_sel.shape[0]):\n    mean = X_train_sel[i].mean()\n    std = X_train_sel[i].std()\n    if std > 0:\n        X_train_sel[i] = (X_train_sel[i] - mean) / std\n\nfor i in range(X_test_sel.shape[0]):\n    mean = X_test_sel[i].mean()\n    std = X_test_sel[i].std()\n    if std > 0:\n        X_test_sel[i] = (X_test_sel[i] - mean) / std\n\n# Recompute covariances with selected channels\nprint(\"\\nRecomputing covariance matrices with selected channels...\")\nX_cov_train_sel = Covariances(estimator=\"lwf\").fit_transform(X_train_sel)\nX_cov_test_sel = Covariances(estimator=\"lwf\").fit_transform(X_test_sel)\n\nprint(f\"New covariance shape: {X_cov_train_sel.shape}\")\n\n# Check condition numbers\neigvals_sel = np.linalg.eigvalsh(X_cov_train_sel)\ncond_numbers_sel = eigvals_sel[:, -1] / (eigvals_sel[:, 0] + 1e-10)\nprint(f\"New mean condition number: {np.mean(cond_numbers_sel):.2f}\")\n\nn_channels_sel = n_select  # Update for deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPD Learn Models\n\nNow we train SPD Learn deep learning models and hybrid approaches:\n\n- **Hybrid TS + MLP**: Tangent space features with a neural network\n- **SPDNet**: End-to-end SPD network on covariance matrices\n- **TSMNet**: Temporal convolutions with SPD pooling\n\n**Using Channel-Selected Data**\n\nWith fewer channels, we expect:\n\n- Lower condition numbers\n- Easier optimization\n- Better generalization\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode import EEGClassifier\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import (\n    EarlyStopping,\n    EpochScoring,\n    GradientNormClipping,\n)\nfrom skorch.dataset import ValidSplit\n\nfrom spd_learn.modules import SPDBatchNormMeanVar, TraceNorm\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\nUsing device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom SPDNet with Trace Normalization\n\nfNIRS signals are very small (hemoglobin concentration changes),\nleading to tiny covariance matrix values. We use TraceNorm from\nspd_learn to normalize matrices to unit trace for stable optimization.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from spd_learn.modules import BiMap, CovLayer, LogEig, ReEig, Shrinkage\n\n\nclass SPDNetWithNorm(torch.nn.Module):\n    \"\"\"SPDNet with trace normalization for pre-computed covariance matrices.\n\n    Uses spd_learn library components with configurations optimized for\n    pre-computed covariance inputs:\n\n    - **TraceNorm**: Normalizes matrices to unit trace (handles scale variations)\n    - **Shrinkage**: Learnable regularization for numerical stability\n    - **BiMap**: Bilinear mapping with ``parametrized=False`` for gradient flow\n    - **ReEig**: Rectified eigenvalue layer\n    - **SPDBatchNormMeanVar**: Riemannian batch normalization (domain adaptation)\n    - **LogEig**: Maps to Euclidean space for classification\n\n    .. note::\n\n        For pre-computed covariances, ``BiMap(parametrized=False)`` is required\n        to enable gradient flow. The default orthogonal parametrization causes\n        gradient vanishing when combined with ReEig/LogEig custom backward\n        functions. This is a known limitation when working with pre-computed\n        SPD matrices. For end-to-end learning from raw time series, use TSMNet\n        which applies CNN preprocessing before SPD operations.\n\n    Parameters\n    ----------\n    n_chans : int\n        Number of channels (size of covariance matrices).\n    n_outputs : int\n        Number of output classes.\n    subspacedim : int, optional\n        Subspace dimension for BiMap. Defaults to n_chans.\n    threshold : float, default=1e-4\n        Eigenvalue threshold for ReEig.\n    use_batchnorm : bool, default=True\n        Whether to use SPDBatchNormMeanVar (recommended for cross-subject evaluation).\n    \"\"\"\n\n    def __init__(\n        self, n_chans, n_outputs, subspacedim=None, threshold=1e-4, use_batchnorm=True\n    ):\n        super().__init__()\n        if subspacedim is None:\n            subspacedim = n_chans\n\n        # Input preprocessing: TraceNorm + Shrinkage for scale normalization\n        self.trace_norm = TraceNorm(epsilon=1e-4)\n        self.shrinkage_input = Shrinkage(\n            n_chans=n_chans, init_shrinkage=0.0, learnable=True\n        )\n\n        # SPDNet layers using library components\n        # BiMap: parametrized=False enables gradient flow with ReEig/LogEig\n        # init_method=\"stiefel\" ensures proper initialization on Stiefel manifold\n        self.bimap = BiMap(\n            n_chans, subspacedim, parametrized=False, init_method=\"stiefel\", seed=42\n        )\n        self.reeig = ReEig(threshold=threshold)\n\n        # SPDBatchNormMeanVar between ReEig and LogEig (helps with domain adaptation)\n        self.use_batchnorm = use_batchnorm\n        if use_batchnorm:\n            self.spdbnorm = SPDBatchNormMeanVar(\n                num_features=subspacedim,\n                affine=True,\n                momentum=0.1,\n            )\n\n        # LogEig maps to tangent space\n        self.logeig = LogEig(upper=True)\n\n        # Classifier\n        self.len_last_layer = subspacedim * (subspacedim + 1) // 2\n        self.classifier = torch.nn.Linear(self.len_last_layer, n_outputs)\n\n    def forward(self, X):\n        # Input preprocessing\n        X = self.trace_norm(X)\n        X = self.shrinkage_input(X)\n\n        # SPDNet: BiMap -> ReEig -> [SPDBatchNormMeanVar] -> LogEig\n        X = self.bimap(X)\n        X = self.reeig(X)\n        if self.use_batchnorm:\n            X = self.spdbnorm(X)\n        X = self.logeig(X)\n\n        return self.classifier(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TSMNet with Gradient Flow\n\nTSMNet applies CNNs to extract temporal features, then uses SPD operations\nfor pooling. However, the library's TSMNet uses BiMap(parametrized=True)\nwhich blocks gradients. We create TSMNetWithGradientFlow with\nBiMap(parametrized=False) to enable proper learning.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TSMNetWithGradientFlow(torch.nn.Module):\n    \"\"\"Tangent Space Mapping Network with gradient flow enabled.\n\n    Similar to spd_learn.TSMNet but uses BiMap(parametrized=False) to\n    enable gradient flow through ReEig/LogEig layers.\n\n    Parameters\n    ----------\n    n_chans : int\n        Number of input channels.\n    n_outputs : int\n        Number of output classes.\n    n_temp_filters : int, default=4\n        Number of temporal convolution filters.\n    temp_kernel_length : int, default=25\n        Temporal kernel length.\n    n_spatiotemp_filters : int, default=40\n        Number of spatiotemporal filters.\n    n_bimap_filters : int, default=20\n        Output dimension of BiMap layer.\n    reeig_threshold : float, default=1e-4\n        Threshold for ReEig layer.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_chans=None,\n        n_outputs=None,\n        n_temp_filters=4,\n        temp_kernel_length=25,\n        n_spatiotemp_filters=40,\n        n_bimap_filters=20,\n        reeig_threshold=1e-4,\n    ):\n        super().__init__()\n\n        self.n_chans = n_chans\n        self.n_outputs = n_outputs\n        self.n_temp_filters = n_temp_filters\n        self.n_temp_kernel = temp_kernel_length\n        self.n_spatiotemp_filters = n_spatiotemp_filters\n        self.n_bimap_filters = n_bimap_filters\n        self.reeig_threshold = reeig_threshold\n\n        n_tangent_dim = int(n_bimap_filters * (n_bimap_filters + 1) / 2)\n\n        # CNN feature extraction\n        self.cnn = torch.nn.Sequential(\n            torch.nn.Conv2d(\n                1,\n                self.n_temp_filters,\n                kernel_size=(1, self.n_temp_kernel),\n                padding=\"same\",\n                padding_mode=\"reflect\",\n            ),\n            torch.nn.Conv2d(\n                self.n_temp_filters, self.n_spatiotemp_filters, (self.n_chans, 1)\n            ),\n            torch.nn.Flatten(start_dim=2),\n        )\n\n        # Covariance pooling from CNN features\n        self.covpool = CovLayer()\n\n        # SPD processing with gradient-flow-enabled BiMap\n        self.bimap = BiMap(\n            in_features=self.n_spatiotemp_filters,\n            out_features=self.n_bimap_filters,\n            parametrized=False,  # Enable gradient flow\n            init_method=\"stiefel\",\n            seed=42,\n        )\n        self.reeig = ReEig(threshold=self.reeig_threshold)\n\n        # Riemannian batch normalization\n        self.spdbnorm = SPDBatchNormMeanVar(\n            self.n_bimap_filters,\n            affine=True,\n            bias_requires_grad=False,\n            weight_requires_grad=True,\n        )\n\n        # Map to tangent space\n        self.logeig = torch.nn.Sequential(\n            LogEig(),\n            torch.nn.Flatten(start_dim=1),\n        )\n\n        # Classification head\n        self.head = torch.nn.Linear(\n            in_features=n_tangent_dim, out_features=self.n_outputs\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input of shape (batch_size, n_chans, n_times).\n\n        Returns\n        -------\n        torch.Tensor\n            Output of shape (batch_size, n_outputs).\n        \"\"\"\n        # CNN feature extraction\n        x_filtered = self.cnn(x[:, None, ...])\n\n        # Covariance pooling (CovLayer computes SCM)\n        x_cov = self.covpool(x_filtered)\n\n        # SPD processing: BiMap -> ReEig -> LogEig\n        x_spd = self.bimap(x_cov)\n        x_spd = self.reeig(x_spd)\n        x_spd = self.spdbnorm(x_spd)\n\n        # Tangent space mapping and classification\n        x_tangent = self.logeig(x_spd)\n        return self.head(x_tangent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hybrid Approach: Tangent Space + MLP\n\nThis approach combines the best of both worlds:\n\n1. Use Riemannian geometry to extract tangent space features\n2. Use a neural network for classification\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"Training Hybrid TS + MLP\")\nprint(\"=\" * 60)\n\n# Get tangent space features from channel-selected covariances\nfrom pyriemann.tangentspace import TangentSpace\n\n\nts_sel = TangentSpace()\nX_ts_train_sel = ts_sel.fit_transform(X_cov_train_sel)\nX_ts_test_sel = ts_sel.transform(X_cov_test_sel)\n\nprint(\n    f\"Tangent space features: {X_ts_train_sel.shape[1]} dimensions (from {n_channels_sel} channels)\"\n)\n\n\n# Simple MLP classifier\nclass SimpleMLP(torch.nn.Module):\n    def __init__(self, n_features, n_hidden, n_outputs, dropout=0.5):\n        super().__init__()\n        self.net = torch.nn.Sequential(\n            torch.nn.Linear(n_features, n_hidden),\n            torch.nn.BatchNorm1d(n_hidden),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(dropout),\n            torch.nn.Linear(n_hidden, n_hidden // 2),\n            torch.nn.BatchNorm1d(n_hidden // 2),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(dropout),\n            torch.nn.Linear(n_hidden // 2, n_outputs),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nn_outputs = len(np.unique(y))\nn_features = X_ts_train_sel.shape[1]\n\nmlp = SimpleMLP(n_features=n_features, n_hidden=64, n_outputs=n_outputs, dropout=0.5)\n\nclf_mlp = NeuralNetClassifier(\n    mlp,\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=1e-3,\n    optimizer__weight_decay=1e-2,\n    train_split=ValidSplit(0.15, stratified=True, random_state=SEED),\n    batch_size=32,\n    max_epochs=20,  # Reduced from 100 for faster documentation build\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n        (\"early_stop\", EarlyStopping(monitor=\"valid_loss\", patience=30)),\n    ],\n    device=device,\n    verbose=1,\n)\n\n# Train on tangent space features from selected channels\nclf_mlp.fit(X_ts_train_sel.astype(np.float32), y_train)\n\n# Evaluate\ny_pred_mlp = clf_mlp.predict(X_ts_test_sel.astype(np.float32))\nacc_mlp = accuracy_score(y_test, y_pred_mlp)\nresults[\"TS + MLP\"] = acc_mlp\nprint(f\"\\nTS + MLP Test Accuracy: {acc_mlp * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SPD Data Augmentation\n\nFor small SPD datasets, we augment by adding small perturbations\nin the tangent space, which preserves the SPD structure.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def augment_spd_data(X_cov, y, n_augment=2, noise_std=0.1):\n    \"\"\"Augment SPD matrices by perturbation in tangent space.\"\"\"\n    from pyriemann.utils.mean import mean_riemann\n    from pyriemann.utils.tangentspace import tangent_space, untangent_space\n\n    # Compute reference point (Riemannian mean)\n    ref = mean_riemann(X_cov)\n\n    # Project to tangent space\n    X_ts = tangent_space(X_cov, ref)\n\n    augmented_cov = [X_cov]\n    augmented_y = [y]\n\n    for _ in range(n_augment):\n        # Add noise in tangent space\n        noise = np.random.randn(*X_ts.shape) * noise_std\n        X_ts_noisy = X_ts + noise\n\n        # Project back to SPD manifold\n        X_aug = untangent_space(X_ts_noisy, ref)\n        augmented_cov.append(X_aug)\n        augmented_y.append(y)\n\n    return np.vstack(augmented_cov), np.hstack(augmented_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training SPDNet with Cross-Validation\n\nUse K-fold CV to better estimate performance on small datasets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"Training SPDNet on fNIRS covariances\")\nprint(\"=\" * 60)\n\nn_outputs = len(np.unique(y))\n\n# Check original covariance statistics\neigvals_orig = np.linalg.eigvalsh(X_cov_train_sel)\ncond_orig = eigvals_orig[:, -1] / (eigvals_orig[:, 0] + 1e-10)\nprint(f\"Original covariances: mean condition number = {np.mean(cond_orig):.2f}\")\nprint(f\"Eigenvalue range: [{eigvals_orig.min():.2e}, {eigvals_orig.max():.2e}]\")\n\n# Use smaller subspace for regularization\nsubspace_dim = max(4, n_channels_sel // 2)\nprint(\n    f\"Using subspace dimension: {subspace_dim} (from {n_channels_sel} selected channels)\"\n)\n\n\n# Create model with TraceNorm from spd_learn library\n# TraceNorm handles the small scale of fNIRS covariances\ndef create_spdnet():\n    model = SPDNetWithNorm(\n        n_chans=n_channels_sel,\n        n_outputs=n_outputs,\n        subspacedim=subspace_dim,\n        threshold=1e-4,\n        use_batchnorm=False,  # Set True for domain adaptation\n    )\n    return model\n\n\nprint(\"Using SPDNetWithNorm (TraceNorm + SPDNet from spd_learn)\")\n\nspdnet = create_spdnet()\nclf_spdnet = EEGClassifier(\n    spdnet,\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=1e-3,\n    optimizer__weight_decay=1e-3,\n    train_split=ValidSplit(0.15, stratified=True, random_state=SEED),\n    batch_size=16,\n    max_epochs=20,  # Reduced from 80 for faster documentation build\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n        (\"early_stop\", EarlyStopping(monitor=\"valid_loss\", patience=30)),\n    ],\n    device=device,\n    verbose=1,\n)\n\n# Train on original covariances (TraceNorm handles normalization)\nclf_spdnet.fit(X_cov_train_sel.astype(np.float32), y_train)\n\n# Evaluate\ny_pred_spdnet = clf_spdnet.predict(X_cov_test_sel.astype(np.float32))\nacc_spdnet = accuracy_score(y_test, y_pred_spdnet)\nresults[\"SPDNet\"] = acc_spdnet\nprint(f\"\\nSPDNet Test Accuracy: {acc_spdnet * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training TSMNet with Data Augmentation\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"Training TSMNet on raw fNIRS signals\")\nprint(\"=\" * 60)\n\n\n# Augment raw signals by adding noise and time shifts\ndef augment_time_series(X, y, n_augment=2, noise_std=0.1, shift_max=5):\n    \"\"\"Augment time series with noise and temporal shifts.\"\"\"\n    augmented_X = [X]\n    augmented_y = [y]\n\n    for _ in range(n_augment):\n        # Add Gaussian noise\n        noise = np.random.randn(*X.shape) * noise_std * np.std(X)\n        X_noisy = X + noise\n\n        # Random temporal shift\n        shift = np.random.randint(-shift_max, shift_max + 1)\n        if shift != 0:\n            X_shifted = np.roll(X_noisy, shift, axis=2)\n        else:\n            X_shifted = X_noisy\n\n        augmented_X.append(X_shifted)\n        augmented_y.append(y)\n\n    return np.vstack(augmented_X), np.hstack(augmented_y)\n\n\n# Use channel-selected time series\nprint(\"Augmenting time series data (selected channels)...\")\nX_aug, y_ts_aug = augment_time_series(\n    X_train_sel, y_train, n_augment=3, noise_std=0.05, shift_max=3\n)\nprint(f\"Original: {len(y_train)} samples -> Augmented: {len(y_ts_aug)} samples\")\n\n# TSMNet configuration optimized for fNIRS with selected channels\ntemp_kernel = min(n_times // 3, 40)\nn_bimap = max(4, n_channels_sel // 2)\n\nprint(\n    f\"TSMNet config: temp_kernel={temp_kernel}, n_bimap_filters={n_bimap}, n_channels={n_channels_sel}\"\n)\n\n# Use TSMNetWithGradientFlow instead of library TSMNet\n# Library TSMNet has BiMap(parametrized=True) which blocks gradients\ntsmnet = TSMNetWithGradientFlow(\n    n_chans=n_channels_sel,\n    n_outputs=n_outputs,\n    n_temp_filters=4,\n    temp_kernel_length=temp_kernel,\n    n_spatiotemp_filters=16,  # Reduced for small data\n    n_bimap_filters=n_bimap,\n    reeig_threshold=1e-4,\n)\n\nclf_tsmnet = EEGClassifier(\n    tsmnet,\n    criterion=torch.nn.CrossEntropyLoss,\n    criterion__label_smoothing=0.1,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=1e-3,\n    optimizer__weight_decay=1e-2,\n    train_split=ValidSplit(0.15, stratified=True, random_state=SEED),\n    batch_size=32,\n    max_epochs=30,  # Reduced from 200 for faster documentation build\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n        (\"grad_clip\", GradientNormClipping(gradient_clip_value=1.0)),\n        (\"early_stop\", EarlyStopping(monitor=\"valid_loss\", patience=50)),\n    ],\n    device=device,\n    verbose=1,\n)\n\n# Shuffle augmented data\nshuffle_idx = np.random.permutation(len(y_ts_aug))\nX_aug = X_aug[shuffle_idx]\ny_ts_aug = y_ts_aug[shuffle_idx]\n\n# Train on augmented data\nclf_tsmnet.fit(X_aug.astype(np.float32), y_ts_aug)\n\n# Evaluate on original test set (selected channels)\ny_pred_tsmnet = clf_tsmnet.predict(X_test_sel.astype(np.float32))\nacc_tsmnet = accuracy_score(y_test, y_pred_tsmnet)\nresults[\"TSMNet\"] = acc_tsmnet\nprint(f\"\\nTSMNet Test Accuracy: {acc_tsmnet * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Comparison\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"RESULTS SUMMARY\")\nprint(\"=\" * 60)\n\n# Create comparison plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\nmethods = list(results.keys())\naccuracies = [results[m] * 100 for m in methods]\n\ncolors = [\"#3498db\", \"#2ecc71\", \"#9b59b6\", \"#e74c3c\", \"#f39c12\"][: len(methods)]\nbars = ax.bar(methods, accuracies, color=colors, edgecolor=\"black\", linewidth=1.5)\n\n# Add value labels on bars\nfor bar, acc in zip(bars, accuracies):\n    height = bar.get_height()\n    ax.annotate(\n        f\"{acc:.1f}%\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 3),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontweight=\"bold\",\n        fontsize=11,\n    )\n\nax.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax.set_title(\"fNIRS Classification: Method Comparison\", fontweight=\"bold\", fontsize=14)\nax.set_ylim(0, 105)\nax.axhline(y=50, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Chance level\")\nax.legend()\nax.grid(True, alpha=0.3, axis=\"y\")\n\nplt.tight_layout()\nplt.savefig(\"fnirs_plot.png\", dpi=100, bbox_inches=\"tight\")\nplt.close()\n\n# Print table\nprint(\"\\n\" + \"-\" * 50)\nprint(f\"{'Method':<20} {'Accuracy':>15}\")\nprint(\"-\" * 50)\nfor method, acc in results.items():\n    print(f\"{method:<20} {acc * 100:>14.2f}%\")\nprint(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrices\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n\npredictions = {\n    \"MDM\": y_pred_mdm,\n    \"TS + MLP\": y_pred_mlp,\n    \"SPDNet\": y_pred_spdnet,\n    \"TSMNet\": y_pred_tsmnet,\n}\n\nfor ax, (name, y_pred) in zip(axes, predictions.items()):\n    ConfusionMatrixDisplay.from_predictions(\n        y_test, y_pred, ax=ax, cmap=\"Blues\", display_labels=[\"Class 0\", \"Class 1\"]\n    )\n    ax.set_title(f\"{name}\\nAcc: {accuracy_score(y_test, y_pred) * 100:.1f}%\")\n\nplt.suptitle(\"Confusion Matrices\", fontweight=\"bold\", fontsize=14)\nplt.tight_layout()\nplt.savefig(\"fnirs_plot.png\", dpi=100, bbox_inches=\"tight\")\nplt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Observations\n\nThis tutorial demonstrated fNIRS classification using SPD Learn:\n\n1. **Real fNIRS data** from the MNE-NIRS motor group dataset provides\n   realistic classification challenges with ~300 trials from 5 subjects\n\n2. **Classical Riemannian methods** (MDM, Tangent Space + LR) provide\n   strong baselines that are robust and require minimal tuning\n\n3. **Hybrid TS + MLP** combines Riemannian geometry with neural networks\n\n4. **SPDNet with proper configuration** can achieve competitive results:\n\n   - Use ``TraceNorm`` to handle scale variations in fNIRS covariances\n   - Use ``Shrinkage`` for learnable regularization\n   - Use ``BiMap(parametrized=False)`` for gradient flow with ReEig/LogEig\n   - Use ``SPDBatchNormMeanVar`` for cross-subject domain adaptation\n\n**Key finding: BiMap configuration for pre-computed covariances**\n\nWhen using SPDNet on pre-computed covariance matrices, ``parametrized=False``\non BiMap is required to enable gradient flow. The default orthogonal\nparametrization causes gradient vanishing when combined with the custom\nbackward functions in ReEig/LogEig.\n\n**Recommendations for fNIRS:**\n\n- **TS + LR**: Best baseline (83% accuracy), fast and robust\n- **SPDNet with TraceNorm**: Competitive (80% accuracy), uses Riemannian layers\n- **TS + MLP**: Good hybrid approach, combines geometry with neural networks\n\n**When to use each approach:**\n\n- SPDBatchNormMeanVar for domain adaptation across sessions/subjects\n- SPDNet when you want learnable Riemannian transformations\n- TS + LR/MLP when you need a robust baseline with minimal tuning\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"fNIRS section completed!\")\nprint(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus: When Deep Learning Excels\n\nWe've seen that classical Riemannian methods outperform deep learning\non real BCI data due to session/subject variability. Now let's\ndemonstrate when deep learning **does** excel:\n\n1. **Large sample sizes** (1000+ trials per class)\n2. **Low condition numbers** (well-conditioned covariances)\n3. **Same distribution** for train and test (no domain shift)\n4. **Complex, non-linear** decision boundaries\n\nWe use simulated SPD data with these characteristics to show SPDNet\noutperforming classical methods.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"BONUS: When Deep Learning Excels (Controlled Simulation)\")\nprint(\"=\" * 60)\n\nfrom pyriemann.datasets import make_gaussian_blobs\n\n\nprint(\"\"\"\nSCENARIO: Large, well-conditioned SPD data with complex class structure\n\nThis simulates a scenario where:\n- Train and test come from the same distribution (no domain shift)\n- Classes have moderate separation (challenging but learnable)\n- Sample size is large enough for deep learning to generalize\n- Covariance matrices are well-conditioned\n\nThis is realistic for applications like:\n- Radar signal classification\n- Medical imaging (when training and test are from same scanner)\n- Industrial monitoring (stable sensor conditions)\n\"\"\")\n\n# Generate large, well-conditioned SPD dataset\nn_sim_samples = 300  # Reduced from 1000 for faster documentation build\nn_sim_channels = 20  # Moderate dimensionality\nn_sim_classes = 2  # Binary classification (make_gaussian_blobs limitation)\n\nprint(\n    f\"Generating {n_sim_samples * 2} samples, {n_sim_channels} channels, {n_sim_classes} classes...\"\n)\n\n# Create SPD matrices with moderate separation (challenging but learnable)\nX_sim_cov, y_sim = make_gaussian_blobs(\n    n_matrices=n_sim_samples,\n    n_dim=n_sim_channels,\n    class_sep=1.5,  # Moderate separation - not too easy, not too hard\n    class_disp=0.8,  # Some within-class variability\n    random_state=SEED,\n    return_centers=False,\n)\n\n# Regularize matrices for better conditioning\nX_sim_cov = X_sim_cov + 1e-3 * np.eye(n_sim_channels)\n\n# Generate time series that have this covariance structure (for TSMNet)\nn_sim_times = 100\nn_total_samples = len(y_sim)  # make_gaussian_blobs returns 2*n_matrices samples\nX_sim = np.zeros((n_total_samples, n_sim_channels, n_sim_times))\nfor i in range(n_total_samples):\n    # Generate time series from covariance using Cholesky decomposition\n    L = np.linalg.cholesky(X_sim_cov[i] + 1e-6 * np.eye(n_sim_channels))\n    X_sim[i] = L @ np.random.randn(n_sim_channels, n_sim_times)\n\n# Split data (same distribution for train/test - key difference from BCI!)\nX_sim_cov_train, X_sim_cov_test, X_sim_train, X_sim_test, y_sim_train, y_sim_test = (\n    train_test_split(\n        X_sim_cov, X_sim, y_sim, test_size=0.3, random_state=SEED, stratify=y_sim\n    )\n)\n\nprint(f\"Train: {len(y_sim_train)} samples, Test: {len(y_sim_test)} samples\")\n\n# Check condition numbers (should be well-behaved)\neigvals_sim = np.linalg.eigvalsh(X_sim_cov_train)\ncond_sim = eigvals_sim[:, -1] / (eigvals_sim[:, 0] + 1e-10)\nprint(f\"Mean condition number: {np.mean(cond_sim):.2f} (much lower than BCI data!)\")\n\nresults_sim = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline: MDM on Simulated Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\" * 50)\nprint(\"Evaluating MDM...\")\nmdm_sim = MDM()\nmdm_sim.fit(X_sim_cov_train, y_sim_train)\ny_pred_mdm_sim = mdm_sim.predict(X_sim_cov_test)\nacc_mdm_sim = accuracy_score(y_sim_test, y_pred_mdm_sim)\nresults_sim[\"MDM\"] = acc_mdm_sim\nprint(f\"MDM Accuracy: {acc_mdm_sim * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline: TS + LR on Simulated Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nEvaluating TS + LR...\")\nts_lr_sim = make_pipeline(\n    TangentSpace(), LogisticRegression(max_iter=1000, random_state=SEED)\n)\nts_lr_sim.fit(X_sim_cov_train, y_sim_train)\ny_pred_ts_lr_sim = ts_lr_sim.predict(X_sim_cov_test)\nacc_ts_lr_sim = accuracy_score(y_sim_test, y_pred_ts_lr_sim)\nresults_sim[\"TS + LR\"] = acc_ts_lr_sim\nprint(f\"TS + LR Accuracy: {acc_ts_lr_sim * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SPDNet on Simulated Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\" * 50)\nprint(\"Training SPDNet...\")\n\n# Use SPDNetWithNorm (TraceNorm + SPDNet) for consistent preprocessing\nspdnet_sim = SPDNetWithNorm(\n    n_chans=n_sim_channels,\n    n_outputs=n_sim_classes,\n    subspacedim=n_sim_channels // 2,  # Good balance\n    threshold=1e-4,\n    use_batchnorm=False,\n)\n\nclf_spdnet_sim = EEGClassifier(\n    spdnet_sim,\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=1e-3,\n    optimizer__weight_decay=1e-3,\n    train_split=ValidSplit(0.15, stratified=True, random_state=SEED),\n    batch_size=64,\n    max_epochs=20,  # Reduced from 80 for faster documentation build\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n        (\"early_stop\", EarlyStopping(monitor=\"valid_loss\", patience=25)),\n    ],\n    device=device,\n    verbose=1,\n)\n\nclf_spdnet_sim.fit(X_sim_cov_train.astype(np.float32), y_sim_train)\n\ny_pred_spdnet_sim = clf_spdnet_sim.predict(X_sim_cov_test.astype(np.float32))\nacc_spdnet_sim = accuracy_score(y_sim_test, y_pred_spdnet_sim)\nresults_sim[\"SPDNet\"] = acc_spdnet_sim\nprint(f\"\\nSPDNet Accuracy: {acc_spdnet_sim * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TSMNet on Simulated Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\" * 50)\nprint(\"Training TSMNet...\")\n\n# Use TSMNetWithGradientFlow instead of library TSMNet\ntsmnet_sim = TSMNetWithGradientFlow(\n    n_chans=n_sim_channels,\n    n_outputs=n_sim_classes,\n    n_temp_filters=4,\n    temp_kernel_length=min(25, n_sim_times // 4),\n    n_spatiotemp_filters=32,\n    n_bimap_filters=n_sim_channels // 2,\n    reeig_threshold=1e-4,\n)\n\nclf_tsmnet_sim = EEGClassifier(\n    tsmnet_sim,\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=1e-3,\n    optimizer__weight_decay=1e-3,\n    train_split=ValidSplit(0.15, stratified=True, random_state=SEED),\n    batch_size=64,\n    max_epochs=20,  # Reduced from 80 for faster documentation build\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n        (\"early_stop\", EarlyStopping(monitor=\"valid_loss\", patience=25)),\n    ],\n    device=device,\n    verbose=1,\n)\n\nclf_tsmnet_sim.fit(X_sim_train.astype(np.float32), y_sim_train)\n\ny_pred_tsmnet_sim = clf_tsmnet_sim.predict(X_sim_test.astype(np.float32))\nacc_tsmnet_sim = accuracy_score(y_sim_test, y_pred_tsmnet_sim)\nresults_sim[\"TSMNet\"] = acc_tsmnet_sim\nprint(f\"\\nTSMNet Accuracy: {acc_tsmnet_sim * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results Summary\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\nprint(\"SIMULATION RESULTS: Deep Learning CAN Win!\")\nprint(\"=\" * 60)\n\nprint(\"\\n\" + \"-\" * 50)\nprint(f\"{'Method':<20} {'Accuracy':>15}\")\nprint(\"-\" * 50)\nfor method, acc in results_sim.items():\n    marker = \" <-- BEST\" if acc == max(results_sim.values()) else \"\"\n    print(f\"{method:<20} {acc * 100:>14.2f}%{marker}\")\nprint(\"-\" * 50)\nprint(f\"{'Condition number':<20} {np.mean(cond_sim):>15.2f}\")\nprint(f\"{'Train size':<20} {len(y_sim_train):>15}\")\nprint(f\"{'Classes':<20} {n_sim_classes:>15}\")\nprint(\"-\" * 50)\n\n# Create comparison plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\nmethods_sim = list(results_sim.keys())\naccuracies_sim = [results_sim[m] * 100 for m in methods_sim]\n\ncolors_sim = [\"#3498db\", \"#2ecc71\", \"#e74c3c\", \"#f39c12\"][: len(methods_sim)]\nbars_sim = ax.bar(\n    methods_sim, accuracies_sim, color=colors_sim, edgecolor=\"black\", linewidth=1.5\n)\n\nfor bar, acc in zip(bars_sim, accuracies_sim):\n    height = bar.get_height()\n    ax.annotate(\n        f\"{acc:.1f}%\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 3),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontweight=\"bold\",\n        fontsize=11,\n    )\n\nax.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax.set_title(\n    \"Controlled Simulation: When Deep Learning Excels\", fontweight=\"bold\", fontsize=14\n)\nax.set_ylim(0, 105)\nax.axhline(y=50, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Chance (2-class)\")\nax.legend()\nax.grid(True, alpha=0.3, axis=\"y\")\n\nplt.tight_layout()\nplt.savefig(\"simulation_results_plot.png\", dpi=100, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"KEY TAKEAWAYS\")\nprint(\"=\" * 60)\n\n# Determine best method\nbest_method = max(results_sim, key=results_sim.get)\nbest_acc = results_sim[best_method]\n\nprint(f\"\"\"\nCOMPARISON: Controlled Simulation vs Real BCI Data\n\nSIMULATION (This section):\n- Best method: {best_method} ({best_acc * 100:.1f}%)\n- Deep learning WORKS because:\n  * Train and test from same distribution\n  * Well-conditioned covariances (cond ~{np.mean(cond_sim):.0f})\n  * Large sample size ({len(y_sim_train)} train samples)\n\nREAL fNIRS DATA (Previous section):\n- Best method: TS + LR (83.3%)\n- Deep learning struggles because:\n  * Cross-subject evaluation (different distributions)\n  * High condition numbers (cond ~2100)\n  * Limited samples per class\n\nWHEN TO USE EACH APPROACH:\n\n| Scenario                          | Recommended Method |\n|-----------------------------------|-------------------|\n| Cross-subject/session BCI         | TS + LR, MDM      |\n| Within-session BCI                | SPDNet, TSMNet    |\n| Large dataset, stable conditions  | SPDNet, TSMNet    |\n| Small dataset (<500 trials)       | TS + LR, MDM      |\n| Domain adaptation needed          | SPDBatchNormMeanVar      |\n| Hybrid approach                   | TS + MLP          |\n\nPRACTICAL WORKFLOW:\n\n1. Start with TS + LR (fast, robust baseline)\n2. If accuracy is good and data is large, try SPDNet/TSMNet\n3. For cross-session/subject, consider SPDBatchNormMeanVar for domain adaptation\n4. For small data, stick with classical Riemannian methods\n\"\"\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Tutorial completed!\")\nprint(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}