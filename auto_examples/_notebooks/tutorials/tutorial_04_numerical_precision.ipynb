{
  "cells": [
    {
      "id": "14b3b0f5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "%pip install -q spd_learn moabb braindecode scikit-learn matplotlib\n\n# For GPU support (recommended for faster training)\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Numerical Precision and Stability for SPD Networks\n\nThis tutorial demonstrates how SPD Learn's numerical stability system works\nand why it's essential for reliable training. We compare models with different\neigenvalue threshold configurations to show the impact on training stability.\n   :depth: 2\n\nThe tutorial is organized into seven experiments:\n\n1. **ReEig Threshold Impact**: Compare different eigenvalue clamping thresholds\n2. **Raw vs Regularized Data**: Effect of data conditioning on stability\n3. **NumericalContext**: Dynamic configuration for different scenarios\n4. **Performance Benchmarking**: Custom backward vs autograd speed comparison\n5. **Stability Landscape**: 2D heatmap of threshold \u00d7 shrinkage parameter space\n6. **Eigenvalue Distribution Analysis**: Deep dive into automatic thresholds\n7. **NumericalConfig Summary**: Using the summary() method for quick inspection\n\n**Estimated runtime**: 8-15 minutes (depending on hardware)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why Numerical Stability Matters\n\nSPD neural networks perform operations like:\n\n- **Matrix logarithm**: Requires strictly positive eigenvalues\n- **Eigendecomposition**: Gradients explode when eigenvalues are nearly equal\n- **Inverse square root**: Small eigenvalues cause numerical overflow\n\nSPD Learn provides a unified numerical configuration system to handle these\nchallenges automatically based on data type and matrix conditioning.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n\n# MOABB for EEG data\nfrom moabb.datasets import BNCI2014_001\nfrom moabb.paradigms import MotorImagery\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# SPD Learn imports\nfrom spd_learn.functional import (\n    NumericalContext,\n    get_epsilon,\n    recommend_dtype_for_spd,\n)\nfrom spd_learn.functional.numerical import numerical_config\nfrom spd_learn.modules import BiMap, CovLayer, LogEig, ReEig, Shrinkage, TraceNorm\n\n\nwarnings.filterwarnings(\"ignore\")\n\n# Set seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Dtype-Aware Thresholds\n\nThe numerical module provides dtype-aware thresholds that automatically\nadjust based on the precision of your data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"DTYPE-AWARE THRESHOLDS\")\nprint(\"=\" * 70)\n\nprint(\"\\nMachine epsilon by dtype:\")\nfor dtype, name in [(torch.float64, \"float64\"), (torch.float32, \"float32\")]:\n    info = torch.finfo(dtype)\n    print(f\"  {name}: eps = {info.eps:.2e}\")\n\nprint(\"\\nDefault eigenvalue clamping thresholds:\")\nfor dtype, name in [(torch.float64, \"float64\"), (torch.float32, \"float32\")]:\n    eps = get_epsilon(dtype, \"eigval_clamp\")\n    print(f\"  {name}: {eps:.2e}\")\n\nprint(\"\\nWith eigval_clamp_scale=1e6 (100x larger threshold):\")\nwith NumericalContext(eigval_clamp_scale=1e6):\n    for dtype, name in [(torch.float64, \"float64\"), (torch.float32, \"float32\")]:\n        eps = get_epsilon(dtype, \"eigval_clamp\")\n        print(f\"  {name}: {eps:.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Real EEG Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"LOADING EEG DATA (BNCI2014_001)\")\nprint(\"=\" * 70)\n\ndataset = BNCI2014_001()\nparadigm = MotorImagery(n_classes=4)\n\ncache_config = dict(\n    save_raw=True,\n    save_epochs=True,\n    save_array=True,\n    use=True,\n    overwrite_raw=False,\n    overwrite_epochs=False,\n    overwrite_array=False,\n)\n\nsubject_id = 1\nX_raw, labels, meta = paradigm.get_data(\n    dataset=dataset, subjects=[subject_id], cache_config=cache_config\n)\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(labels)\n\ntrain_idx = meta.query(\"session == '0train'\").index.to_numpy()\ntest_idx = meta.query(\"session == '1test'\").index.to_numpy()\n\nX_train_raw = torch.from_numpy(X_raw[train_idx]).float()\ny_train = torch.from_numpy(y[train_idx]).long()\nX_test_raw = torch.from_numpy(X_raw[test_idx]).float()\ny_test = torch.from_numpy(y[test_idx]).long()\n\nn_channels = X_train_raw.shape[1]\nn_classes = len(label_encoder.classes_)\n\nprint(f\"Subject {subject_id}: Train={len(y_train)}, Test={len(y_test)}\")\nprint(f\"Channels: {n_channels}, Classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Covariance Properties\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"COVARIANCE MATRIX ANALYSIS\")\nprint(\"=\" * 70)\n\ncov_layer = CovLayer()\n\nwith torch.no_grad():\n    X_train_cov = cov_layer(X_train_raw)\n    X_test_cov = cov_layer(X_test_raw)\n\neigvals_train = torch.linalg.eigvalsh(X_train_cov)\ncond_numbers = eigvals_train.max(dim=-1).values / eigvals_train.min(\n    dim=-1\n).values.clamp(min=1e-10)\n\nprint(\"\\nRaw Covariance Statistics:\")\nprint(\n    f\"  Condition number: Median={cond_numbers.median():.0f}, Max={cond_numbers.max():.0f}\"\n)\nprint(f\"  Min eigenvalue: {eigvals_train.min():.2e}\")\nprint(f\"  Max eigenvalue: {eigvals_train.max():.2e}\")\nprint(f\"  Recommended dtype: {recommend_dtype_for_spd(cond_numbers.median().item())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Regularized Data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trace_norm = TraceNorm(epsilon=1e-5)\nshrinkage = Shrinkage(n_chans=n_channels, init_shrinkage=0.3, learnable=False)\n\nwith torch.no_grad():\n    X_train_reg = shrinkage(trace_norm(X_train_cov.clone()))\n    X_test_reg = shrinkage(trace_norm(X_test_cov.clone()))\n\neigvals_reg = torch.linalg.eigvalsh(X_train_reg)\ncond_reg = eigvals_reg.max(dim=-1).values / eigvals_reg.min(dim=-1).values\n\nprint(\"\\nAfter Regularization (TraceNorm + Shrinkage):\")\nprint(f\"  Condition number: Median={cond_reg.median():.1f}, Max={cond_reg.max():.1f}\")\nprint(f\"  Min eigenvalue: {eigvals_reg.min():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom SPDNet with Configurable Threshold\n\nWe create a custom SPDNet class where we can configure the ReEig threshold.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SPDNetConfigurable(nn.Module):\n    \"\"\"SPDNet with configurable ReEig threshold.\"\"\"\n\n    def __init__(self, n_chans, n_outputs, threshold=None, use_autograd=False):\n        super().__init__()\n        self.bimap = BiMap(n_chans, n_chans)\n        self.reeig = ReEig(threshold=threshold, autograd=use_autograd)\n        self.logeig = LogEig(upper=True)\n        self.len_last_layer = n_chans * (n_chans + 1) // 2\n        self.classifier = nn.Linear(self.len_last_layer, n_outputs)\n\n    def forward(self, X):\n        X = self.bimap(X)\n        X = self.reeig(X)\n        X = self.logeig(X)\n        X = self.classifier(X)\n        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(\n    model, X_train, X_test, y_train, y_test, epochs=80, lr=5e-4, verbose=True\n):\n    \"\"\"Train SPDNet with monitoring.\"\"\"\n    model = model.to(DEVICE)\n    X_train_d = X_train.to(DEVICE)\n    X_test_d = X_test.to(DEVICE)\n    y_train_d = y_train.to(DEVICE)\n    y_test_d = y_test.to(DEVICE)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n\n    history = {\n        \"train_loss\": [],\n        \"train_acc\": [],\n        \"test_acc\": [],\n        \"nan_count\": 0,\n        \"grad_explosions\": 0,\n    }\n\n    dataset = TensorDataset(X_train_d, y_train_d)\n    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        correct = 0\n        total = 0\n\n        for X_batch, y_batch in loader:\n            optimizer.zero_grad()\n\n            try:\n                outputs = model(X_batch)\n\n                if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n                    history[\"nan_count\"] += 1\n                    continue\n\n                loss = criterion(outputs, y_batch)\n\n                if torch.isnan(loss) or torch.isinf(loss):\n                    history[\"nan_count\"] += 1\n                    continue\n\n                loss.backward()\n\n                # Check gradients\n                bad_grad = False\n                max_grad = 0\n                for p in model.parameters():\n                    if p.grad is not None:\n                        if torch.isnan(p.grad).any() or torch.isinf(p.grad).any():\n                            bad_grad = True\n                            break\n                        max_grad = max(max_grad, p.grad.abs().max().item())\n\n                if bad_grad:\n                    history[\"nan_count\"] += 1\n                    continue\n\n                if max_grad > 1e6:\n                    history[\"grad_explosions\"] += 1\n\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n\n                epoch_loss += loss.item() * len(y_batch)\n                _, predicted = outputs.max(1)\n                correct += predicted.eq(y_batch).sum().item()\n                total += len(y_batch)\n\n            except RuntimeError:\n                history[\"nan_count\"] += 1\n                continue\n\n        scheduler.step()\n\n        if total > 0:\n            history[\"train_loss\"].append(epoch_loss / total)\n            history[\"train_acc\"].append(100.0 * correct / total)\n        else:\n            history[\"train_loss\"].append(float(\"nan\"))\n            history[\"train_acc\"].append(0.0)\n\n        model.eval()\n        with torch.no_grad():\n            try:\n                test_out = model(X_test_d)\n                if not (torch.isnan(test_out).any() or torch.isinf(test_out).any()):\n                    _, pred = test_out.max(1)\n                    test_acc = 100.0 * pred.eq(y_test_d).sum().item() / len(y_test_d)\n                else:\n                    test_acc = 0.0\n            except RuntimeError:\n                test_acc = 0.0\n        history[\"test_acc\"].append(test_acc)\n\n        if verbose and (epoch + 1) % 20 == 0:\n            print(\n                f\"  Epoch {epoch + 1}: Loss={history['train_loss'][-1]:.4f}, \"\n                f\"Train={history['train_acc'][-1]:.1f}%, Test={test_acc:.1f}%\"\n            )\n\n    history[\"best_test_acc\"] = max(history[\"test_acc\"]) if history[\"test_acc\"] else 0.0\n    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 1: Impact of ReEig Threshold\n\nCompare different eigenvalue clamping thresholds on regularized data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 1: IMPACT OF REEIG THRESHOLD\")\nprint(\"=\" * 70)\nprint(\"\\nComparing different eigenvalue thresholds on regularized data...\")\n\nthreshold_results = {}\n\nthresholds = [\n    (\"threshold=1e-10\", 1e-10),\n    (\"threshold=1e-6\", 1e-6),\n    (\"threshold=1e-4\", 1e-4),\n    (\"threshold=1e-2\", 1e-2),\n    (\"threshold=None (auto)\", None),  # Uses numerical config based on dtype\n]\n\nfor name, threshold in thresholds:\n    print(f\"\\n--- {name} ---\")\n    model = SPDNetConfigurable(n_channels, n_classes, threshold=threshold)\n    history = train_model(model, X_train_reg, X_test_reg, y_train, y_test, epochs=60)\n    threshold_results[name] = history\n    status = (\n        \"STABLE\"\n        if history[\"nan_count\"] == 0\n        else f\"UNSTABLE ({history['nan_count']} NaN)\"\n    )\n    print(\n        f\"Best: {history['best_test_acc']:.1f}%, Status: {status}, Grad explosions: {history['grad_explosions']}\"\n    )\n\n# Visualize\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\ncolors = {\n    \"threshold=1e-10\": \"#c0392b\",\n    \"threshold=1e-6\": \"#e74c3c\",\n    \"threshold=1e-4\": \"#3498db\",\n    \"threshold=1e-2\": \"#f39c12\",\n    \"threshold=None (auto)\": \"#27ae60\",\n}\n\n# Training loss\nax1 = axes[0]\nfor name, hist in threshold_results.items():\n    # Extract short label: \"threshold=1e-10\" -> \"1e-10\", \"threshold=None (auto)\" -> \"auto\"\n    short_label = name.replace(\"threshold=\", \"\").replace(\" (auto)\", \"\")\n    if short_label == \"None\":\n        short_label = \"auto\"\n    ax1.plot(hist[\"train_loss\"], label=short_label, color=colors[name], linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Training Loss\", fontsize=12)\nax1.set_title(\"Training Loss\", fontsize=13, fontweight=\"bold\")\nax1.legend(fontsize=9)\nax1.grid(True, alpha=0.3)\n\n# Test accuracy\nax2 = axes[1]\nfor name, hist in threshold_results.items():\n    short_label = name.replace(\"threshold=\", \"\").replace(\" (auto)\", \"\")\n    if short_label == \"None\":\n        short_label = \"auto\"\n    ax2.plot(hist[\"test_acc\"], label=short_label, color=colors[name], linewidth=2)\nax2.axhline(y=25, color=\"gray\", linestyle=\"--\", alpha=0.5)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Test Accuracy (%)\", fontsize=12)\nax2.set_title(\"Test Accuracy\", fontsize=13, fontweight=\"bold\")\nax2.legend(fontsize=9)\nax2.grid(True, alpha=0.3)\nax2.set_ylim([0, 80])\n\n# Summary bars\nax3 = axes[2]\nnames = list(threshold_results.keys())\naccs = [threshold_results[n][\"best_test_acc\"] for n in names]\nnans = [threshold_results[n][\"nan_count\"] for n in names]\ncolor_list = [colors[n] for n in names]\n\nbars = ax3.barh(range(len(names)), accs, color=color_list, edgecolor=\"black\")\nax3.set_yticks(range(len(names)))\n# Create readable y-tick labels\ny_labels = []\nfor n in names:\n    label = n.replace(\"threshold=\", \"\")\n    y_labels.append(label)\nax3.set_yticklabels(y_labels, fontsize=9)\nax3.set_xlabel(\"Best Test Accuracy (%)\", fontsize=12)\nax3.set_title(\"Best Performance\", fontsize=13, fontweight=\"bold\")\n\nfor i, (acc, nan) in enumerate(zip(accs, nans)):\n    label = f\"{acc:.1f}%\" if nan == 0 else f\"{acc:.1f}% (NaN)\"\n    color = \"green\" if nan == 0 else \"red\"\n    ax3.text(acc + 1, i, label, va=\"center\", fontsize=9, fontweight=\"bold\", color=color)\n\nax3.set_xlim([0, 80])\nax3.grid(True, alpha=0.3, axis=\"x\")\n\nplt.suptitle(\n    \"Experiment 1: Impact of ReEig Threshold on Training\",\n    fontsize=14,\n    fontweight=\"bold\",\n    y=1.02,\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 2: Raw vs Regularized Data\n\nCompare training on raw (ill-conditioned) vs regularized (well-conditioned) data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 2: RAW VS REGULARIZED DATA\")\nprint(\"=\" * 70)\n\ndata_results = {}\n\n# Raw data\nprint(\"\\n--- Raw data (\u03ba \u2248 12000) ---\")\nmodel_raw = SPDNetConfigurable(n_channels, n_classes, threshold=1e-4)\nhistory_raw = train_model(\n    model_raw, X_train_cov, X_test_cov, y_train, y_test, epochs=80\n)\ndata_results[\"Raw (\u03ba\u224812k)\"] = history_raw\n\n# Regularized data\nprint(\"\\n--- Regularized data (\u03ba \u2248 13) ---\")\nmodel_reg = SPDNetConfigurable(n_channels, n_classes, threshold=1e-4)\nhistory_reg = train_model(\n    model_reg, X_train_reg, X_test_reg, y_train, y_test, epochs=80\n)\ndata_results[\"Regularized (\u03ba\u224813)\"] = history_reg\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\ndata_colors = {\"Raw (\u03ba\u224812k)\": \"#e74c3c\", \"Regularized (\u03ba\u224813)\": \"#27ae60\"}\n\nax1 = axes[0]\nfor name, hist in data_results.items():\n    ax1.plot(hist[\"train_loss\"], label=name, color=data_colors[name], linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Training Loss\", fontsize=12)\nax1.set_title(\"Training Loss\", fontsize=13, fontweight=\"bold\")\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\nax2 = axes[1]\nfor name, hist in data_results.items():\n    ax2.plot(\n        hist[\"test_acc\"],\n        label=f\"{name} (best: {hist['best_test_acc']:.1f}%)\",\n        color=data_colors[name],\n        linewidth=2,\n    )\nax2.axhline(y=25, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Chance\")\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Test Accuracy (%)\", fontsize=12)\nax2.set_title(\"Test Accuracy\", fontsize=13, fontweight=\"bold\")\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\nax2.set_ylim([0, 100])\n\nplt.suptitle(\n    \"Experiment 2: Raw vs Regularized Data\", fontsize=14, fontweight=\"bold\", y=1.02\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 3: NumericalContext for Dynamic Configuration\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 3: NumericalContext DEMONSTRATION\")\nprint(\"=\" * 70)\n\nprint(\"\\n1. Default thresholds:\")\nprint(f\"   eigval_clamp: {get_epsilon(torch.float32, 'eigval_clamp'):.2e}\")\nprint(f\"   eigval_log:   {get_epsilon(torch.float32, 'eigval_log'):.2e}\")\n\nprint(\"\\n2. With eigval_clamp_scale=1e6, eigval_log_scale=1e4:\")\nwith NumericalContext(eigval_clamp_scale=1e6, eigval_log_scale=1e4):\n    print(f\"   eigval_clamp: {get_epsilon(torch.float32, 'eigval_clamp'):.2e}\")\n    print(f\"   eigval_log:   {get_epsilon(torch.float32, 'eigval_log'):.2e}\")\n\nprint(\"\\n3. After context (restored):\")\nprint(f\"   eigval_clamp: {get_epsilon(torch.float32, 'eigval_clamp'):.2e}\")\nprint(f\"   eigval_log:   {get_epsilon(torch.float32, 'eigval_log'):.2e}\")\n\n# Compare dtype-aware model with different contexts\nprint(\"\\n4. Training with different NumericalContext configurations:\")\n\ncontext_results = {}\n\n# Default context\nprint(\"\\n--- eigval_clamp_scale=1e4 (default) ---\")\nmodel_default = SPDNetConfigurable(n_channels, n_classes, threshold=None)\nhistory_default = train_model(\n    model_default, X_train_reg, X_test_reg, y_train, y_test, epochs=60\n)\ncontext_results[\"eigval_clamp_scale=1e4\"] = history_default\n\n# Larger scale context (more aggressive clamping)\nprint(\"\\n--- eigval_clamp_scale=1e6 (larger threshold) ---\")\nwith NumericalContext(eigval_clamp_scale=1e6, eigval_log_scale=1e4):\n    model_large_scale = SPDNetConfigurable(n_channels, n_classes, threshold=None)\n    history_large_scale = train_model(\n        model_large_scale, X_train_reg, X_test_reg, y_train, y_test, epochs=60\n    )\ncontext_results[\"eigval_clamp_scale=1e6\"] = history_large_scale\n\n# Visualize\nfig, ax = plt.subplots(figsize=(10, 4))\n\nctx_colors = {\"eigval_clamp_scale=1e4\": \"#3498db\", \"eigval_clamp_scale=1e6\": \"#27ae60\"}\n\nfor name, hist in context_results.items():\n    ax.plot(\n        hist[\"test_acc\"],\n        label=f\"{name} (best: {hist['best_test_acc']:.1f}%)\",\n        color=ctx_colors[name],\n        linewidth=2,\n    )\n\nax.axhline(y=25, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Chance\")\nax.set_xlabel(\"Epoch\", fontsize=12)\nax.set_ylabel(\"Test Accuracy (%)\", fontsize=12)\nax.set_title(\n    \"Test Accuracy with Different NumericalContext Configurations\",\n    fontsize=13,\n    fontweight=\"bold\",\n)\nax.legend(fontsize=11)\nax.grid(True, alpha=0.3)\nax.set_ylim([0, 80])\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 4: Performance Benchmarking\n\nCompare performance between custom backward pass and autograd,\nacross different dtypes. SPD Learn uses custom backward passes for\neigendecomposition operations which can be faster than autograd.\nLarger matrix sizes are more numerically demanding (eigenvalues are\nmore densely packed), so 128 and 256 highlight stability-sensitive regimes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 4: PERFORMANCE BENCHMARKING\")\nprint(\"=\" * 70)\nprint(\"Note: Larger matrices (128/256) are more sensitive to numerical issues.\")\nprint(\"      If you see NaNs or unstable gradients, increase eigval_clamp_scale.\")\n\n\ndef benchmark(func, *args, n_runs=50):\n    \"\"\"Benchmark function returning mean time in milliseconds.\"\"\"\n    # Warmup runs\n    for _ in range(3):\n        func(*args)\n    if DEVICE == \"cuda\":\n        torch.cuda.synchronize()\n\n    # Timed runs\n    start = time.perf_counter()\n    for _ in range(n_runs):\n        func(*args)\n    if DEVICE == \"cuda\":\n        torch.cuda.synchronize()\n    elapsed = time.perf_counter() - start\n    return (elapsed / n_runs) * 1000  # Convert to milliseconds\n\n\n# Matrix sizes to test (include larger sizes for stability stress)\nmatrix_sizes = [8, 16, 22, 32, 64, 128, 256]\n\n# Store results\nbenchmark_results = {\n    \"sizes\": matrix_sizes,\n    \"custom_f32\": [],\n    \"autograd_f32\": [],\n    \"custom_f64\": [],\n    \"autograd_f64\": [],\n}\n\nprint(\"\\nBenchmarking forward+backward pass times...\")\nprint(\"(This may take a minute)\")\n\nfor size in matrix_sizes:\n    print(f\"\\n  Matrix size: {size}x{size}\")\n\n    for dtype, dtype_name in [(torch.float32, \"f32\"), (torch.float64, \"f64\")]:\n        # Create test data\n        X_bench = torch.randn(32, size, size, dtype=dtype, device=DEVICE)\n        X_bench = X_bench @ X_bench.transpose(-1, -2) + 0.1 * torch.eye(\n            size, dtype=dtype, device=DEVICE\n        )\n        X_bench.requires_grad_(True)\n\n        # Custom backward\n        reeig_custom = ReEig(threshold=1e-4, autograd=False).to(DEVICE)\n\n        def forward_custom():\n            if X_bench.grad is not None:\n                X_bench.grad.zero_()\n            out = reeig_custom(X_bench)\n            loss = out.sum()\n            loss.backward()\n\n        time_custom = benchmark(forward_custom, n_runs=30)\n        benchmark_results[f\"custom_{dtype_name}\"].append(time_custom)\n        print(f\"    Custom ({dtype_name}): {time_custom:.3f} ms\")\n\n        # Autograd\n        reeig_auto = ReEig(threshold=1e-4, autograd=True).to(DEVICE)\n\n        def forward_autograd():\n            if X_bench.grad is not None:\n                X_bench.grad.zero_()\n            out = reeig_auto(X_bench)\n            loss = out.sum()\n            loss.backward()\n\n        time_autograd = benchmark(forward_autograd, n_runs=30)\n        benchmark_results[f\"autograd_{dtype_name}\"].append(time_autograd)\n        print(f\"    Autograd ({dtype_name}): {time_autograd:.3f} ms\")\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left panel: Log-scale timing comparison\nax1 = axes[0]\nax1.semilogy(\n    matrix_sizes,\n    benchmark_results[\"custom_f32\"],\n    \"o-\",\n    color=\"#3498db\",\n    linewidth=2,\n    markersize=8,\n    label=\"Custom (float32)\",\n)\nax1.semilogy(\n    matrix_sizes,\n    benchmark_results[\"autograd_f32\"],\n    \"s--\",\n    color=\"#e74c3c\",\n    linewidth=2,\n    markersize=8,\n    label=\"Autograd (float32)\",\n)\nax1.semilogy(\n    matrix_sizes,\n    benchmark_results[\"custom_f64\"],\n    \"o-\",\n    color=\"#2980b9\",\n    linewidth=2,\n    markersize=8,\n    alpha=0.6,\n    label=\"Custom (float64)\",\n)\nax1.semilogy(\n    matrix_sizes,\n    benchmark_results[\"autograd_f64\"],\n    \"s--\",\n    color=\"#c0392b\",\n    linewidth=2,\n    markersize=8,\n    alpha=0.6,\n    label=\"Autograd (float64)\",\n)\nax1.set_xlabel(\"Matrix Size\", fontsize=12)\nax1.set_ylabel(\"Time (ms, log scale)\", fontsize=12)\nax1.set_title(\"Forward+Backward Pass Timing\", fontsize=13, fontweight=\"bold\")\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3, which=\"both\")\nax1.set_xticks(matrix_sizes)\n\n# Right panel: Speedup ratio bar chart\nax2 = axes[1]\nspeedup_f32 = [\n    a / c\n    for a, c in zip(benchmark_results[\"autograd_f32\"], benchmark_results[\"custom_f32\"])\n]\nspeedup_f64 = [\n    a / c\n    for a, c in zip(benchmark_results[\"autograd_f64\"], benchmark_results[\"custom_f64\"])\n]\n\nx = np.arange(len(matrix_sizes))\nwidth = 0.35\n\nbars1 = ax2.bar(\n    x - width / 2,\n    speedup_f32,\n    width,\n    label=\"float32\",\n    color=\"#3498db\",\n    edgecolor=\"black\",\n)\nbars2 = ax2.bar(\n    x + width / 2,\n    speedup_f64,\n    width,\n    label=\"float64\",\n    color=\"#2980b9\",\n    edgecolor=\"black\",\n)\nax2.axhline(y=1.0, color=\"gray\", linestyle=\"--\", alpha=0.7, label=\"Break-even\")\nax2.set_xlabel(\"Matrix Size\", fontsize=12)\nax2.set_ylabel(\"Speedup (Autograd / Custom)\", fontsize=12)\nax2.set_title(\"Custom Backward Speedup\", fontsize=13, fontweight=\"bold\")\nax2.set_xticks(x)\nax2.set_xticklabels(matrix_sizes)\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3, axis=\"y\")\n\n# Add value labels\nfor bar in bars1:\n    height = bar.get_height()\n    ax2.text(\n        bar.get_x() + bar.get_width() / 2,\n        height + 0.05,\n        f\"{height:.1f}x\",\n        ha=\"center\",\n        fontsize=9,\n    )\nfor bar in bars2:\n    height = bar.get_height()\n    ax2.text(\n        bar.get_x() + bar.get_width() / 2,\n        height + 0.05,\n        f\"{height:.1f}x\",\n        ha=\"center\",\n        fontsize=9,\n    )\n\nplt.suptitle(\n    \"Experiment 4: Custom vs Autograd Performance\",\n    fontsize=14,\n    fontweight=\"bold\",\n    y=1.02,\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 5: Stability Landscape\n\nVisualize the stability/accuracy landscape across different\nthreshold and shrinkage parameter combinations using a 2D heatmap.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 5: STABILITY LANDSCAPE\")\nprint(\"=\" * 70)\nprint(\"\\nMapping stability across threshold \u00d7 shrinkage parameter space...\")\nprint(\"(This will take several minutes - 64 configurations \u00d7 20 epochs each)\")\n\n# Parameter grids (8x8 = 64 combinations)\nthreshold_values = np.logspace(-10, -1, 8)  # 1e-10 to 1e-1\nshrinkage_values = np.linspace(0.0, 0.8, 8)  # 0% to 80%\n\n# Results storage\naccuracy_grid = np.zeros((len(shrinkage_values), len(threshold_values)))\nstability_grid = np.zeros((len(shrinkage_values), len(threshold_values)))\nnan_grid = np.zeros((len(shrinkage_values), len(threshold_values)))\n\n\ndef quick_train(model, X_tr, X_te, y_tr, y_te, epochs=20):\n    \"\"\"Quick training for landscape exploration.\"\"\"\n    model = model.to(DEVICE)\n    X_tr_d, X_te_d = X_tr.to(DEVICE), X_te.to(DEVICE)\n    y_tr_d, y_te_d = y_tr.to(DEVICE), y_te.to(DEVICE)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n\n    nan_count = 0\n    best_acc = 0.0\n\n    dataset = TensorDataset(X_tr_d, y_tr_d)\n    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n    for epoch in range(epochs):\n        model.train()\n        for X_batch, y_batch in loader:\n            optimizer.zero_grad()\n            try:\n                outputs = model(X_batch)\n                if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n                    nan_count += 1\n                    continue\n                loss = criterion(outputs, y_batch)\n                if torch.isnan(loss) or torch.isinf(loss):\n                    nan_count += 1\n                    continue\n                loss.backward()\n                # Check gradients\n                bad_grad = False\n                for p in model.parameters():\n                    if p.grad is not None and (\n                        torch.isnan(p.grad).any() or torch.isinf(p.grad).any()\n                    ):\n                        bad_grad = True\n                        break\n                if bad_grad:\n                    nan_count += 1\n                    continue\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n            except RuntimeError:\n                nan_count += 1\n                continue\n\n        # Evaluate\n        model.eval()\n        with torch.no_grad():\n            try:\n                test_out = model(X_te_d)\n                if not (torch.isnan(test_out).any() or torch.isinf(test_out).any()):\n                    _, pred = test_out.max(1)\n                    acc = 100.0 * pred.eq(y_te_d).sum().item() / len(y_te_d)\n                    best_acc = max(best_acc, acc)\n            except RuntimeError:\n                pass\n\n    is_stable = nan_count == 0\n    return best_acc, is_stable, nan_count\n\n\ntotal_configs = len(shrinkage_values) * len(threshold_values)\nconfig_num = 0\n\nfor i, shrink in enumerate(shrinkage_values):\n    for j, thresh in enumerate(threshold_values):\n        config_num += 1\n        if config_num % 16 == 0 or config_num == 1:\n            print(f\"  Progress: {config_num}/{total_configs} configurations...\")\n\n        # Apply shrinkage to raw covariance\n        if shrink > 0:\n            shrink_layer = Shrinkage(\n                n_chans=n_channels, init_shrinkage=shrink, learnable=False\n            )\n            with torch.no_grad():\n                X_tr_shrink = shrink_layer(trace_norm(X_train_cov.clone()))\n                X_te_shrink = shrink_layer(trace_norm(X_test_cov.clone()))\n        else:\n            X_tr_shrink = trace_norm(X_train_cov.clone())\n            X_te_shrink = trace_norm(X_test_cov.clone())\n\n        # Create model with specific threshold\n        model = SPDNetConfigurable(n_channels, n_classes, threshold=thresh)\n        acc, stable, nans = quick_train(\n            model, X_tr_shrink, X_te_shrink, y_train, y_test, epochs=20\n        )\n\n        accuracy_grid[i, j] = acc\n        stability_grid[i, j] = 1.0 if stable else 0.0\n        nan_grid[i, j] = nans\n\nprint(\"  Landscape mapping complete!\")\n\n# Visualize\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# Common axis labels\nlog_thresh = np.log10(threshold_values)\nextent = [\n    log_thresh.min(),\n    log_thresh.max(),\n    shrinkage_values.min(),\n    shrinkage_values.max(),\n]\n\n# Panel 1: Accuracy heatmap\nax1 = axes[0]\nim1 = ax1.pcolormesh(\n    log_thresh,\n    shrinkage_values,\n    accuracy_grid,\n    cmap=\"RdYlGn\",\n    shading=\"auto\",\n    vmin=25,\n    vmax=70,\n)\ncs1 = ax1.contour(\n    log_thresh,\n    shrinkage_values,\n    accuracy_grid,\n    levels=[30, 40, 50, 60],\n    colors=\"black\",\n    linewidths=0.5,\n    alpha=0.5,\n)\nax1.clabel(cs1, inline=True, fontsize=8, fmt=\"%.0f%%\")\nax1.set_xlabel(\"log\u2081\u2080(Threshold)\", fontsize=12)\nax1.set_ylabel(\"Shrinkage\", fontsize=12)\nax1.set_title(\"Test Accuracy (%)\", fontsize=13, fontweight=\"bold\")\nplt.colorbar(im1, ax=ax1, label=\"Accuracy (%)\")\n\n# Panel 2: Stability map\nax2 = axes[1]\nim2 = ax2.pcolormesh(\n    log_thresh,\n    shrinkage_values,\n    stability_grid,\n    cmap=\"RdYlGn\",\n    shading=\"auto\",\n    vmin=0,\n    vmax=1,\n)\nax2.set_xlabel(\"log\u2081\u2080(Threshold)\", fontsize=12)\nax2.set_ylabel(\"Shrinkage\", fontsize=12)\nax2.set_title(\"Stability (Green=Stable)\", fontsize=13, fontweight=\"bold\")\ncbar2 = plt.colorbar(im2, ax=ax2)\ncbar2.set_ticks([0, 1])\ncbar2.set_ticklabels([\"Unstable\", \"Stable\"])\n\n# Panel 3: NaN event count\nax3 = axes[2]\nim3 = ax3.pcolormesh(\n    log_thresh,\n    shrinkage_values,\n    nan_grid,\n    cmap=\"Reds\",\n    shading=\"auto\",\n)\ncs3 = ax3.contour(\n    log_thresh,\n    shrinkage_values,\n    nan_grid,\n    levels=[5, 10, 20],\n    colors=\"black\",\n    linewidths=0.5,\n    alpha=0.7,\n)\nax3.clabel(cs3, inline=True, fontsize=8, fmt=\"%.0f\")\nax3.set_xlabel(\"log\u2081\u2080(Threshold)\", fontsize=12)\nax3.set_ylabel(\"Shrinkage\", fontsize=12)\nax3.set_title(\"NaN Event Count\", fontsize=13, fontweight=\"bold\")\nplt.colorbar(im3, ax=ax3, label=\"NaN Events\")\n\nplt.suptitle(\n    \"Experiment 5: Stability Landscape (Threshold \u00d7 Shrinkage)\",\n    fontsize=14,\n    fontweight=\"bold\",\n    y=1.02,\n)\nplt.tight_layout()\nplt.show()\n\n# Print key findings\nprint(\"\\nKey observations from stability landscape:\")\nbest_idx = np.unravel_index(np.argmax(accuracy_grid), accuracy_grid.shape)\nprint(\n    f\"  Best accuracy: {accuracy_grid[best_idx]:.1f}% at \"\n    f\"shrinkage={shrinkage_values[best_idx[0]]:.2f}, \"\n    f\"threshold={threshold_values[best_idx[1]]:.1e}\"\n)\nstable_mask = stability_grid == 1.0\nstable_accs = accuracy_grid[stable_mask]\nif len(stable_accs) > 0:\n    print(f\"  Stable configurations: {stable_mask.sum()}/{total_configs}\")\n    print(f\"  Best stable accuracy: {stable_accs.max():.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 6: Eigenvalue Distribution Analysis\n\nDeep dive into the automatic threshold system by visualizing\neigenvalue distributions with threshold overlays showing \"danger zones.\"\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 6: EIGENVALUE DISTRIBUTION ANALYSIS\")\nprint(\"=\" * 70)\n\n# Collect eigenvalues\neigvals_raw = torch.linalg.eigvalsh(X_train_cov).flatten().numpy()\neigvals_reg = torch.linalg.eigvalsh(X_train_reg).flatten().numpy()\n\n# Get thresholds for different dtypes\nthresholds_by_dtype = {}\nfor dtype, name in [\n    (torch.float16, \"float16\"),\n    (torch.float32, \"float32\"),\n    (torch.float64, \"float64\"),\n]:\n    thresholds_by_dtype[name] = get_epsilon(dtype, \"eigval_clamp\")\n\nprint(\"\\nAutomatic thresholds by dtype:\")\nfor name, thresh in thresholds_by_dtype.items():\n    print(f\"  {name}: {thresh:.2e}\")\n\n# Count at-risk eigenvalues\nprint(\"\\nEigenvalues at risk (below threshold):\")\nfor dtype_name, thresh in thresholds_by_dtype.items():\n    raw_at_risk = (eigvals_raw < thresh).sum()\n    reg_at_risk = (eigvals_reg < thresh).sum()\n    print(\n        f\"  {dtype_name}: Raw={raw_at_risk}/{len(eigvals_raw)}, \"\n        f\"Regularized={reg_at_risk}/{len(eigvals_reg)}\"\n    )\n\n# Visualize\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Top-left: Raw eigenvalue histogram with thresholds\nax1 = axes[0, 0]\nax1.hist(\n    eigvals_raw,\n    bins=50,\n    color=\"#3498db\",\n    alpha=0.7,\n    edgecolor=\"black\",\n    label=\"Raw eigenvalues\",\n)\ncolors_thresh = {\"float16\": \"#e74c3c\", \"float32\": \"#f39c12\", \"float64\": \"#27ae60\"}\nfor dtype_name, thresh in thresholds_by_dtype.items():\n    ax1.axvline(\n        x=thresh,\n        color=colors_thresh[dtype_name],\n        linestyle=\"--\",\n        linewidth=2,\n        label=f\"{dtype_name} threshold\",\n    )\n# Shade danger zone\nax1.axvspan(\n    eigvals_raw.min(),\n    thresholds_by_dtype[\"float32\"],\n    alpha=0.2,\n    color=\"red\",\n    label=\"Danger zone (float32)\",\n)\nax1.set_xlabel(\"Eigenvalue\", fontsize=12)\nax1.set_ylabel(\"Count\", fontsize=12)\nax1.set_title(\"Raw Covariance Eigenvalues\", fontsize=13, fontweight=\"bold\")\nax1.legend(fontsize=9)\nax1.set_xscale(\"log\")\nax1.grid(True, alpha=0.3)\n\n# Top-right: Regularized eigenvalue histogram\nax2 = axes[0, 1]\nax2.hist(\n    eigvals_reg,\n    bins=50,\n    color=\"#27ae60\",\n    alpha=0.7,\n    edgecolor=\"black\",\n    label=\"Regularized eigenvalues\",\n)\nfor dtype_name, thresh in thresholds_by_dtype.items():\n    ax2.axvline(\n        x=thresh,\n        color=colors_thresh[dtype_name],\n        linestyle=\"--\",\n        linewidth=2,\n        label=f\"{dtype_name} threshold\",\n    )\nax2.set_xlabel(\"Eigenvalue\", fontsize=12)\nax2.set_ylabel(\"Count\", fontsize=12)\nax2.set_title(\"Regularized Covariance Eigenvalues\", fontsize=13, fontweight=\"bold\")\nax2.legend(fontsize=9)\nax2.set_xscale(\"log\")\nax2.grid(True, alpha=0.3)\n\n# Bottom-left: CDF plot\nax3 = axes[1, 0]\nsorted_raw = np.sort(eigvals_raw)\nsorted_reg = np.sort(eigvals_reg)\ncdf_raw = np.arange(1, len(sorted_raw) + 1) / len(sorted_raw)\ncdf_reg = np.arange(1, len(sorted_reg) + 1) / len(sorted_reg)\n\nax3.plot(sorted_raw, cdf_raw, color=\"#3498db\", linewidth=2, label=\"Raw\")\nax3.plot(sorted_reg, cdf_reg, color=\"#27ae60\", linewidth=2, label=\"Regularized\")\nfor dtype_name, thresh in thresholds_by_dtype.items():\n    ax3.axvline(x=thresh, color=colors_thresh[dtype_name], linestyle=\"--\", linewidth=2)\n    # Add marker at CDF value\n    cdf_val_raw = (sorted_raw < thresh).sum() / len(sorted_raw)\n    ax3.plot(thresh, cdf_val_raw, \"o\", color=colors_thresh[dtype_name], markersize=8)\nax3.set_xlabel(\"Eigenvalue\", fontsize=12)\nax3.set_ylabel(\"CDF\", fontsize=12)\nax3.set_title(\"Cumulative Distribution Function\", fontsize=13, fontweight=\"bold\")\nax3.legend(fontsize=10)\nax3.set_xscale(\"log\")\nax3.grid(True, alpha=0.3)\n\n# Bottom-right: At-risk eigenvalue counts\nax4 = axes[1, 1]\ndtypes = list(thresholds_by_dtype.keys())\nraw_counts = [(eigvals_raw < thresholds_by_dtype[d]).sum() for d in dtypes]\nreg_counts = [(eigvals_reg < thresholds_by_dtype[d]).sum() for d in dtypes]\n\nx = np.arange(len(dtypes))\nwidth = 0.35\nbars1 = ax4.bar(\n    x - width / 2, raw_counts, width, label=\"Raw\", color=\"#e74c3c\", edgecolor=\"black\"\n)\nbars2 = ax4.bar(\n    x + width / 2,\n    reg_counts,\n    width,\n    label=\"Regularized\",\n    color=\"#27ae60\",\n    edgecolor=\"black\",\n)\nax4.set_xlabel(\"Data Type\", fontsize=12)\nax4.set_ylabel(\"At-Risk Eigenvalues\", fontsize=12)\nax4.set_title(\"Eigenvalues Below Threshold\", fontsize=13, fontweight=\"bold\")\nax4.set_xticks(x)\nax4.set_xticklabels(dtypes)\nax4.legend(fontsize=10)\nax4.grid(True, alpha=0.3, axis=\"y\")\n\n# Add count labels\nfor bar in bars1:\n    height = bar.get_height()\n    if height > 0:\n        ax4.text(\n            bar.get_x() + bar.get_width() / 2,\n            height + 0.5,\n            f\"{int(height)}\",\n            ha=\"center\",\n            fontsize=10,\n            fontweight=\"bold\",\n        )\nfor bar in bars2:\n    height = bar.get_height()\n    if height > 0:\n        ax4.text(\n            bar.get_x() + bar.get_width() / 2,\n            height + 0.5,\n            f\"{int(height)}\",\n            ha=\"center\",\n            fontsize=10,\n            fontweight=\"bold\",\n        )\n\nplt.suptitle(\n    \"Experiment 6: Eigenvalue Distribution & Threshold Analysis\",\n    fontsize=14,\n    fontweight=\"bold\",\n    y=1.02,\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXPERIMENT 7: NumericalConfig Summary\n\nDemonstrate the new summary() method for inspecting the complete\nnumerical configuration at a glance.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 7: NUMERICAL CONFIG SUMMARY\")\nprint(\"=\" * 70)\n\nprint(\"\\n--- Default scales, dtype=torch.float32 ---\")\nprint(numerical_config.summary(torch.float32))\n\nprint(\"\\n--- Default scales, dtype=torch.float64 ---\")\nprint(numerical_config.summary(torch.float64))\n\nprint(\n    \"\\n--- Modified: eigval_clamp_scale=1e6, eigval_log_scale=1e4, dtype=torch.float32 ---\"\n)\nwith NumericalContext(eigval_clamp_scale=1e6, eigval_log_scale=1e4):\n    from spd_learn.functional.numerical import numerical_config as nc\n\n    print(nc.summary(torch.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Recommendations\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"SUMMARY: NUMERICAL STABILITY RECOMMENDATIONS\")\nprint(\"=\" * 70)\n\nprint(\"\"\"\n+------------------------------------------------------------------------+\n|                   NUMERICAL CONFIGURATION GUIDE                         |\n+------------------------------------------------------------------------+\n| SCENARIO                  | RECOMMENDED SETTINGS                        |\n+------------------------------------------------------------------------+\n| Well-conditioned (\u03ba<100)  | - eigval_clamp_scale=1e4 (default)         |\n|                           | - Regularization optional                   |\n+------------------------------------------------------------------------+\n| Typical EEG (\u03ba~1000)      | - Light regularization (shrinkage~0.1)     |\n|                           | - Consider eigval_clamp_scale=1e5          |\n+------------------------------------------------------------------------+\n| Ill-conditioned (\u03ba>10k)   | - ReEig threshold protects automatically   |\n|                           | - Consider eigval_clamp_scale=1e6          |\n|                           | - Light regularization may help            |\n+------------------------------------------------------------------------+\n| Mixed precision (fp16)    | - Requires eigval_clamp_scale=1e6-1e8      |\n|                           | - Strong regularization required           |\n+------------------------------------------------------------------------+\n\nIMPORTANT INSIGHT:\nThe built-in ReEig layer with its eigenvalue threshold provides automatic\nprotection against numerical instabilities. Raw EEG covariances with high\ncondition numbers (\u03ba\u224812000) can still be processed stably AND often retain\nmore discriminative information than heavily regularized data.\n\nOver-regularization can hurt performance! The key is finding the right\nbalance for your specific task.\n\nKEY FINDINGS:\n\"\"\")\n\nprint(\"1. THRESHOLD IMPACT:\")\nfor name, hist in threshold_results.items():\n    status = (\n        \"STABLE\" if hist[\"nan_count\"] == 0 else f\"UNSTABLE ({hist['nan_count']} NaN)\"\n    )\n    print(f\"   {name}: {hist['best_test_acc']:.1f}% ({status})\")\n\nprint(\"\\n2. DATA CONDITIONING:\")\nprint(f\"   Raw data (\u03ba\u224812k): {history_raw['best_test_acc']:.1f}%\")\nprint(f\"   Regularized (\u03ba\u224813): {history_reg['best_test_acc']:.1f}%\")\n\nprint(\"\\n3. NUMERICAL CONTEXT (dtype-aware threshold):\")\nfor name, hist in context_results.items():\n    print(f\"   {name}: {hist['best_test_acc']:.1f}%\")\n\nprint(\"\\n4. PERFORMANCE (Custom backward vs Autograd):\")\navg_speedup = np.mean(speedup_f32)\nprint(f\"   Average speedup (float32): {avg_speedup:.1f}x\")\n\nprint(\"\\n5. STABILITY LANDSCAPE:\")\nprint(f\"   Stable configurations: {stable_mask.sum()}/{total_configs}\")\nif len(stable_accs) > 0:\n    print(f\"   Best stable accuracy: {stable_accs.max():.1f}%\")\n\nprint(\"\"\"\nRECOMMENDED WORKFLOW:\n\n1. Check data conditioning:\n   >>> eigvals = torch.linalg.eigvalsh(covariances)\n   >>> condition = eigvals.max() / eigvals.min()\n   >>> print(f\"Condition number: {condition.median():.0f}\")\n\n2. Inspect your numerical configuration:\n   >>> from spd_learn.functional.numerical import numerical_config\n   >>> print(numerical_config.summary(torch.float32))\n\n3. Try training without regularization first:\n   - The ReEig layer provides automatic protection\n   - Raw data often contains more discriminative information\n\n4. If training is unstable, apply light regularization:\n   >>> from spd_learn.modules import TraceNorm, Shrinkage\n   >>> trace_norm = TraceNorm(epsilon=1e-5)\n   >>> shrinkage = Shrinkage(n_chans=22, init_shrinkage=0.1)  # Light shrinkage\n   >>> regularized = shrinkage(trace_norm(covariances))\n\n5. Use dtype-aware thresholds for flexibility:\n   >>> layer = ReEig(threshold=None)  # Auto-adjusts based on dtype\n\n6. Use NumericalContext for temporary configuration:\n   >>> from spd_learn.functional import NumericalContext\n   >>> with NumericalContext(eigval_clamp_scale=1e6):\n   ...     outputs = model(challenging_data)\n\n7. Consider performance trade-offs:\n   - Custom backward passes are typically faster than autograd\n   - Use autograd=True only when debugging gradient issues\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Summary Plot\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot 1: Threshold comparison\nax1 = axes[0, 0]\nnames = list(threshold_results.keys())\naccs = [threshold_results[n][\"best_test_acc\"] for n in names]\ncolor_list = [colors[n] for n in names]\n# Create short labels for x-axis\nshort_labels = []\nfor n in names:\n    short = n.replace(\"threshold=\", \"\").replace(\" (auto)\", \"\")\n    if short == \"None\":\n        short = \"auto\"\n    short_labels.append(short)\nbars = ax1.bar(range(len(names)), accs, color=color_list, edgecolor=\"black\")\nax1.set_xticks(range(len(names)))\nax1.set_xticklabels(short_labels, fontsize=9)\nax1.set_ylabel(\"Best Accuracy (%)\", fontsize=12)\nax1.set_title(\"ReEig Threshold Impact\", fontsize=13, fontweight=\"bold\")\nax1.set_ylim([0, 80])\nax1.axhline(y=25, color=\"gray\", linestyle=\"--\", alpha=0.5)\nax1.grid(True, alpha=0.3, axis=\"y\")\n\n# Plot 2: Data conditioning\nax2 = axes[0, 1]\ndata_names = list(data_results.keys())\ndata_accs = [data_results[n][\"best_test_acc\"] for n in data_names]\ndata_color_list = [data_colors[n] for n in data_names]\nbars = ax2.bar(data_names, data_accs, color=data_color_list, edgecolor=\"black\")\nax2.set_ylabel(\"Best Accuracy (%)\", fontsize=12)\nax2.set_title(\"Data Conditioning Impact\", fontsize=13, fontweight=\"bold\")\nax2.set_ylim([0, 100])\nax2.axhline(y=25, color=\"gray\", linestyle=\"--\", alpha=0.5)\nfor bar, acc in zip(bars, data_accs):\n    ax2.text(\n        bar.get_x() + bar.get_width() / 2,\n        bar.get_height() + 2,\n        f\"{acc:.1f}%\",\n        ha=\"center\",\n        fontsize=11,\n        fontweight=\"bold\",\n    )\nax2.grid(True, alpha=0.3, axis=\"y\")\n\n# Plot 3: Performance comparison\nax3 = axes[1, 0]\nx = np.arange(len(matrix_sizes))\nwidth = 0.35\nbars1 = ax3.bar(\n    x - width / 2,\n    benchmark_results[\"custom_f32\"],\n    width,\n    label=\"Custom\",\n    color=\"#3498db\",\n    edgecolor=\"black\",\n)\nbars2 = ax3.bar(\n    x + width / 2,\n    benchmark_results[\"autograd_f32\"],\n    width,\n    label=\"Autograd\",\n    color=\"#e74c3c\",\n    edgecolor=\"black\",\n)\nax3.set_xlabel(\"Matrix Size\", fontsize=12)\nax3.set_ylabel(\"Time (ms)\", fontsize=12)\nax3.set_title(\"Forward+Backward Performance (float32)\", fontsize=13, fontweight=\"bold\")\nax3.set_xticks(x)\nax3.set_xticklabels(matrix_sizes)\nax3.legend(fontsize=10)\nax3.grid(True, alpha=0.3, axis=\"y\")\n\n# Plot 4: Stability landscape summary (accuracy heatmap)\nax4 = axes[1, 1]\nim4 = ax4.pcolormesh(\n    np.log10(threshold_values),\n    shrinkage_values,\n    accuracy_grid,\n    cmap=\"RdYlGn\",\n    shading=\"auto\",\n    vmin=25,\n    vmax=70,\n)\n# Mark best configuration\nbest_idx = np.unravel_index(np.argmax(accuracy_grid), accuracy_grid.shape)\nax4.plot(\n    np.log10(threshold_values[best_idx[1]]),\n    shrinkage_values[best_idx[0]],\n    \"k*\",\n    markersize=15,\n    label=f\"Best: {accuracy_grid[best_idx]:.1f}%\",\n)\nax4.set_xlabel(\"log\u2081\u2080(Threshold)\", fontsize=12)\nax4.set_ylabel(\"Shrinkage\", fontsize=12)\nax4.set_title(\"Stability Landscape (Accuracy)\", fontsize=13, fontweight=\"bold\")\nax4.legend(loc=\"upper right\", fontsize=10)\nplt.colorbar(im4, ax=ax4, label=\"Accuracy (%)\")\n\nplt.suptitle(\n    \"Summary: Numerical Stability in SPD Networks\",\n    fontsize=14,\n    fontweight=\"bold\",\n    y=1.02,\n)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"TUTORIAL COMPLETE\")\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}