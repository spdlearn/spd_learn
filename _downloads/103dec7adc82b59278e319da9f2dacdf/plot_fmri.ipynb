{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# SPD Learn Example\n# ==================\n#\n# First, install the required packages:\n\n!uv pip install -q spd_learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifying fMRI data with SPDNet\n\nThis example demonstrates how to use **spd_learn**'s\n:class:`SPDNet` to distinguish autism spectrum disorder (ASD)\nfrom typical controls (TC) with resting-state fMRI from the **ABIDE\nPre-processed Connectome Project** :cite:p:`nielsen2014abnormal`.\n\nThis example compares the performance of the :class:`SPDNet` with a\nstronge and robust baseline classifier that uses the tangent space of the\ncovariance matrices, followed by a linear classifier\n(:class:`sklearn.linear_model.LogisticRegression`).\n\nMore details about the baseline can be found in the benchmark\n:cite:p:`dadi2019benchmarking`.\n\nThe results show that the SPDNet have competitive results the baseline, even\nif don't reach the state-of-the-art performance.\n\nThis tutorial shows how to:\n\n- Fetch the ABIDE preprocessed connectome project (PCP) dataset using\n  nilearn :cite:p:`nilearn`.\n- The dataset contains resting-state fMRI time-series of 400 subjects.\n- Compute the covariance matrices of the time-series.\n- Train a :class:`SPDNet` on the training set.\n- Evaluate the model on the held-out test set.\n\nYou can cut runtime further by lowering ``N_SUBJECTS`` or removing the\nvariable to use the full dataset.\n\nThe code have strong similarities with the braindecode example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Imports & configuration\n# -----------------------\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom braindecode import EEGClassifier\nfrom nilearn import datasets\nfrom nilearn.connectome import ConnectivityMeasure\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom spd_learn.models import SPDNet\n\n\nSEED = 42\nN_SUBJECTS = 400\n\n# Set random seeds for reproducibility\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetching the ABIDE Dataset\n\nThe ABIDE (Autism Brain Imaging Data Exchange) dataset contains\nresting-state fMRI data from multiple sites. We use the CC200 atlas\nparcellation which extracts time-series from 200 brain regions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "abide = datasets.fetch_abide_pcp(\n    derivatives=[\"rois_cc200\"],\n    n_subjects=N_SUBJECTS,\n    verbose=1,\n)\n\nts = abide.rois_cc200\nphenotypic = abide.phenotypic\n\n# Create diagnosis: 0 for control, 1 for autism\ny = phenotypic[\"DX_GROUP\"].replace({2: 0, 1: 1}).to_numpy()\n\nprint(f\"Labels: {np.unique(y, return_counts=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Dataset\n\nLet's visualize a sample time-series and compute a sample connectivity\nmatrix to understand the data structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute sample covariance matrices for visualization\ncovariance_viz = ConnectivityMeasure(kind=\"correlation\")\nsample_corr = covariance_viz.fit_transform([ts[0]])[0]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n# Plot sample time-series (first 10 ROIs, first 100 time points)\nax1 = axes[0]\ntime_points = min(100, ts[0].shape[0])\nn_rois_show = 10\nfor i in range(n_rois_show):\n    ax1.plot(ts[0][:time_points, i], alpha=0.7, label=f\"ROI {i + 1}\")\nax1.set_xlabel(\"Time (TRs)\")\nax1.set_ylabel(\"BOLD Signal\")\nax1.set_title(\"Sample fMRI Time-Series\\n(10 ROIs)\", fontweight=\"bold\")\nax1.grid(True, alpha=0.3)\n\n# Plot correlation matrix\nax2 = axes[1]\nim = ax2.imshow(sample_corr, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\nax2.set_xlabel(\"ROI\")\nax2.set_ylabel(\"ROI\")\nax2.set_title(\"Sample Correlation Matrix\\n(200 x 200)\", fontweight=\"bold\")\nplt.colorbar(im, ax=ax2, shrink=0.8, label=\"Correlation\")\n\n# Plot class distribution\nax3 = axes[2]\nunique, counts = np.unique(y, return_counts=True)\ncolors = [\"#3498db\", \"#e74c3c\"]\nbars = ax3.bar([\"Control\", \"Autism\"], counts, color=colors, alpha=0.8)\nax3.set_ylabel(\"Number of Subjects\")\nax3.set_title(\"Class Distribution\\n(ABIDE Dataset)\", fontweight=\"bold\")\nax3.grid(True, alpha=0.3, axis=\"y\")\nfor bar, count in zip(bars, counts):\n    ax3.text(\n        bar.get_x() + bar.get_width() / 2,\n        bar.get_height() + 2,\n        str(count),\n        ha=\"center\",\n        fontweight=\"bold\",\n    )\n\nplt.suptitle(f\"ABIDE Dataset Overview (N={N_SUBJECTS})\", fontsize=14, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the connectivity matrices\n\nHere, we compute the covariance matrices of the time-series\nusing the :class:`nilearn.connectome.ConnectivityMeasure` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covariance = ConnectivityMeasure(kind=\"covariance\")\n\nX = np.array([covariance.fit_transform([t])[0] for t in ts])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting the data\n\nAs we are handle few instance scenary, we will use a stratified split\nto ensure that the training and test sets have the same proportion of\nclasses as the original dataset. This is important to ensure that the\nmodel is trained and evaluated on a representative sample of the data.\n\nWe select 10% of the data for testing, and the rest for training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.1,\n    shuffle=True,\n    stratify=y,\n    random_state=SEED,\n)\n\nprint(\n    f\"Train set shape: {X_train.shape} with {len(X_train)} instances \\\n      Test set shape: {X_test.shape} with {len(X_test)} instances\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the models\nIn this section, we train the :class:`SPDNet` and a baseline\nclassifier that uses the tangent space of the covariance matrices\nfollowed by a linear classifier.\n\nWe use the :class:`EEGClassifier` from **braindecode** to\ntrain the :class:`SPDNet`. The :class:`EEGClassifier` is a\nwrapper around the PyTorch model that provides a convenient interface\nfor training and evaluating the model. It handles the training loop,\nvalidation, and testing of the model, as well as the optimization of\nthe model parameters.\n\nThe baseline classifier uses the tangent space of the covariance\nmatrices, which is a common approach in machine learning for\nclassifying covariance matrices. The tangent space is a linear\napproximation of the manifold of covariance matrices, which allows\nus to use linear classifiers on the covariance matrices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyriemann.tangentspace import TangentSpace\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.pipeline import make_pipeline\nfrom skorch.callbacks import EarlyStopping\nfrom skorch.dataset import ValidSplit\n\n\nclf = make_pipeline(\n    TangentSpace(),\n    LogisticRegression(random_state=SEED),\n)\n\n\nclf_deep = EEGClassifier(\n    # The model is a PyTorch module, so we need to pass it as a callable\n    # to the EEGClassifier.\n    module=SPDNet,\n    module__input_type=\"cov\",\n    module__n_chans=X_train.shape[1],\n    module__n_outputs=len(np.unique(y_train)),\n    module__subspacedim=X_train.shape[1],\n    # the rest of the parameters are related to the training\n    # and validation of the model.\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    train_split=ValidSplit(0.1, stratified=True, random_state=SEED),\n    max_epochs=100,\n    batch_size=64,\n    lr=0.01,\n    callbacks=[\n        \"accuracy\",\n        EarlyStopping(\n            monitor=\"valid_loss\",\n            patience=10,\n        ),\n    ],\n    compile=True,\n)\n\n\nclf.fit(X_train, y_train)\nclf_deep.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\ny_pred_deep = clf_deep.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "acc_baseline = balanced_accuracy_score(y_test, y_pred)\nacc_deep = balanced_accuracy_score(y_test, y_pred_deep)\n\nprint(f\"Test bal accuracy tang space: {acc_baseline * 100:.1f}%\")\nprint(f\"Test bal accuracy SPDNet: {acc_deep * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the results\n\nWe can also visualize the confusion matrices for both models to get a\nbetter understanding of their performance. The confusion matrix shows\nthe number of correct and incorrect predictions for each class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Increase font size for better readability\nplt.rcParams.update({\"font.size\": 12})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\nConfusionMatrixDisplay.from_predictions(\n    y_test,\n    y_pred,\n    ax=axes[0],\n    display_labels=[\"Control\", \"Autism\"],\n    cmap=\"Blues\",\n)\naxes[0].set_title(\"Tangent Space + Logistic Regression\")\n\nConfusionMatrixDisplay.from_predictions(\n    y_test,\n    y_pred_deep,\n    ax=axes[1],\n    display_labels=[\"Control\", \"Autism\"],\n    cmap=\"Blues\",\n)\naxes[1].set_title(\"SPDNet\")\n\nfig.suptitle(\"Confusion matrices on the test set\", fontsize=16)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Cleanup\nimport matplotlib.pyplot as plt\nplt.close('all')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}