{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# SPD Learn Example\n# ==================\n#\n# First, install the required packages:\n\n!uv pip install -q spd_learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Filter Bank Motor Imagery with TensorCSPNet\n\nThis tutorial demonstrates how to use TensorCSPNet for motor imagery\nclassification with filter bank features. TensorCSPNet is designed to\nprocess multi-frequency EEG data by stacking covariance matrices from\ndifferent frequency bands into a tensor structure.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nMotor imagery (MI) is a mental process where a person imagines performing\na motor action without actually executing it. EEG-based brain-computer\ninterfaces (BCIs) can decode these imagined movements to control devices.\n\nFilter bank approaches decompose the EEG signal into multiple frequency\nbands, allowing the model to capture frequency-specific spatial patterns.\nTensorCSPNet :cite:p:`ju2022tensor` leverages this by creating SPD (Symmetric\nPositive\nDefinite) covariance matrices for each frequency band and processing\nthem through a geometry-aware neural network.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n\nFirst, we import the necessary libraries. We use:\n\n- **MOABB**: For loading standardized EEG datasets\n- **Braindecode**: For the EEGClassifier wrapper\n- **SPD Learn**: For the TensorCSPNet model\n- **scikit-learn**: For evaluation metrics and pipelines\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nimport matplotlib.pyplot as plt\nimport moabb\nimport torch\n\nfrom braindecode import EEGClassifier\nfrom einops.layers.torch import Rearrange\nfrom moabb.datasets import BNCI2014_001\nfrom moabb.paradigms import FilterBankMotorImagery\nfrom sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom skorch.callbacks import EpochScoring\nfrom skorch.dataset import ValidSplit\nfrom torch import nn\n\nfrom spd_learn.models import TensorCSPNet\n\n\n# Set logging and ignore warnings for cleaner output\nmoabb.set_log_level(\"info\")\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Dataset\n\nWe use the BCI Competition IV Dataset 2a (BNCI2014_001)\n:cite:p:`tangermann2012review`, which\ncontains EEG recordings from 9 subjects performing 4 different motor\nimagery tasks:\n\n- Left hand movement\n- Right hand movement\n- Both feet movement\n- Tongue movement\n\nThe dataset has 22 EEG channels and was recorded at 250 Hz.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = BNCI2014_001()\nprint(f\"Dataset: {dataset.code}\")\nprint(f\"Number of subjects: {len(dataset.subject_list)}\")\nprint(\"Number of sessions per subject: 2 (train + test)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Filter Bank\n\nWe define a filter bank covering the mu (8-12 Hz) and beta (12-30 Hz)\nrhythms, which are known to be modulated during motor imagery\n:cite:p:`pfurtscheller1999event`.\nEach filter extracts a specific frequency band from the EEG signal.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filters = [\n    [4, 8],  # Theta band\n    [8, 12],  # Mu/Alpha band\n    [12, 16],  # Low beta\n    [16, 20],  # Mid beta\n    [20, 24],  # High beta\n    [24, 28],  # Beta/Gamma transition\n    [28, 32],  # Low gamma\n    [32, 36],  # Gamma\n    [36, 40],  # High gamma\n]\n\nprint(f\"Number of frequency bands: {len(filters)}\")\nprint(\"Frequency bands (Hz):\")\nfor i, (low, high) in enumerate(filters):\n    print(f\"  Band {i + 1}: {low}-{high} Hz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the Paradigm\n\nThe FilterBankMotorImagery paradigm from MOABB handles:\n\n- Filtering the data into multiple frequency bands\n- Extracting epochs around motor imagery events\n- Organizing data in the format (n_trials, n_channels, n_times, n_filters)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = FilterBankMotorImagery(n_classes=4, filters=filters)\nprint(f\"\\nParadigm: {paradigm}\")\nprint(\"Number of classes: 4 (left hand, right hand, feet, tongue)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the TensorCSPNet Model\n\nTensorCSPNet :cite:p:`ju2022tensor` is a deep learning architecture designed\nfor filter\nbank EEG classification. The architecture consists of:\n\n1. **Tensor Stacking**: Organizes multi-band covariance matrices\n2. **BiMap Layers**: Learns spatial filters on the SPD manifold\n3. **Temporal Convolution**: Captures temporal dynamics\n4. **Classification Head**: Final prediction layer\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The input to TensorCSPNet has shape (batch, channels, time, frequencies).\n   We use einops to rearrange from MOABB's format (batch, channels, time, freq)\n   to the expected format.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Training hyperparameters\nbatch_size = 16\nmax_epochs = 15  # Reduced from 50 for faster documentation build\nlearning_rate = 1e-3\n\n# Check for GPU availability\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\nUsing device: {device}\")\n\n# Create the model pipeline\n# We wrap TensorCSPNet with a Rearrange layer to handle the input format\nmodel = nn.Sequential(\n    Rearrange(\"b c t f -> b f c t\"),  # Rearrange to (batch, freq, channels, time)\n    TensorCSPNet(\n        n_chans=22,  # Number of EEG channels\n        n_outputs=4,  # Number of classes\n        n_freqs=len(filters),  # Number of frequency bands\n    ),\n)\n\nprint(\"\\nModel architecture:\")\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the Classifier\n\nWe use Braindecode's EEGClassifier, which is built on top of skorch\nand provides a scikit-learn compatible interface for training\nPyTorch models.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = EEGClassifier(\n    model,\n    criterion=torch.nn.CrossEntropyLoss,\n    optimizer=torch.optim.AdamW,\n    optimizer__lr=learning_rate,\n    optimizer__weight_decay=1e-4,\n    train_split=ValidSplit(0.1, stratified=True, random_state=42),\n    batch_size=batch_size,\n    max_epochs=max_epochs,\n    callbacks=[\n        (\n            \"train_acc\",\n            EpochScoring(\n                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n            ),\n        ),\n    ],\n    device=device,\n    verbose=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Function\n\nWe define a function to train and evaluate the model on a single subject.\nThis function:\n\n1. Loads the data for the subject\n2. Splits into training and test sets (using session info)\n3. Trains the model\n4. Evaluates on both train and test sets\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate_subject(subject: int) -> dict:\n    \"\"\"Train and evaluate TensorCSPNet on a single subject.\n\n    Parameters\n    ----------\n    subject : int\n        Subject ID to evaluate.\n\n    Returns\n    -------\n    dict\n        Dictionary containing accuracy scores and predictions.\n    \"\"\"\n    print(f\"\\n{'=' * 50}\")\n    print(f\"Evaluating Subject {subject}\")\n    print(f\"{'=' * 50}\")\n\n    # Cache configuration for faster repeated runs\n    cache_config = dict(\n        save_raw=True,\n        save_epochs=True,\n        save_array=True,\n        use=True,\n        overwrite_raw=False,\n        overwrite_epochs=False,\n        overwrite_array=False,\n    )\n\n    # Load data for this subject\n    X, labels, meta = paradigm.get_data(\n        dataset=dataset, subjects=[subject], cache_config=cache_config\n    )\n\n    # Encode labels to integers\n    le = LabelEncoder()\n    y = le.fit_transform(labels)\n\n    print(f\"Data shape: {X.shape}\")\n    print(f\"Labels: {le.classes_}\")\n\n    # Split into train and test using session information\n    # Session '0train' is for training, '1test' is for testing\n    train_idx = meta.query(\"session == '0train'\").index.to_numpy()\n    test_idx = meta.query(\"session == '1test'\").index.to_numpy()\n\n    print(f\"Training samples: {len(train_idx)}\")\n    print(f\"Test samples: {len(test_idx)}\")\n\n    # Train the model\n    clf.fit(X[train_idx], y[train_idx])\n\n    # Get predictions\n    y_pred_train = clf.predict(X[train_idx])\n    y_pred_test = clf.predict(X[test_idx])\n\n    # Calculate accuracies\n    train_acc = accuracy_score(y[train_idx], y_pred_train)\n    test_acc = accuracy_score(y[test_idx], y_pred_test)\n\n    print(f\"\\nResults for Subject {subject}:\")\n    print(f\"  Train Accuracy: {train_acc * 100:.2f}%\")\n    print(f\"  Test Accuracy:  {test_acc * 100:.2f}%\")\n\n    return {\n        \"subject\": subject,\n        \"train_acc\": train_acc,\n        \"test_acc\": test_acc,\n        \"y_true_test\": y[test_idx],\n        \"y_pred_test\": y_pred_test,\n        \"label_encoder\": le,\n        \"history\": clf.history,\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Evaluation\n\nFor demonstration purposes, we evaluate on a single subject.\nIn practice, you would loop over all subjects for a complete benchmark.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Training deep learning models on EEG data can take several minutes\n   per subject, depending on your hardware.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Evaluate on subject 1 (you can change this or loop over all subjects)\nsubject_id = 1\nresults = evaluate_subject(subject_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Training History\n\nLet's plot the training and validation loss curves to understand\nhow the model learned over epochs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Extract history\nhistory = results[\"history\"]\nepochs = range(1, len(history) + 1)\n\n# Plot loss\nax1 = axes[0]\nax1.plot(epochs, history[:, \"train_loss\"], \"b-\", label=\"Train Loss\", linewidth=2)\nax1.plot(epochs, history[:, \"valid_loss\"], \"r--\", label=\"Valid Loss\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Training and Validation Loss\", fontsize=14)\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3)\n\n# Plot accuracy\nax2 = axes[1]\nax2.plot(epochs, history[:, \"train_acc\"], \"b-\", label=\"Train Acc\", linewidth=2)\nax2.plot(epochs, history[:, \"valid_acc\"], \"r--\", label=\"Valid Acc\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy\", fontsize=12)\nax2.set_title(\"Training and Validation Accuracy\", fontsize=14)\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\nax2.set_ylim([0, 1])\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix\n\nThe confusion matrix shows how well the model distinguishes between\ndifferent motor imagery classes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n\n# Get class names\nclass_names = results[\"label_encoder\"].classes_\n\n# Compute confusion matrix\ncm = confusion_matrix(results[\"y_true_test\"], results[\"y_pred_test\"])\n\n# Plot\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\nax.set_title(\n    f\"Confusion Matrix - Subject {subject_id}\\n\"\n    f\"Test Accuracy: {results['test_acc'] * 100:.2f}%\",\n    fontsize=14,\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\nIn this tutorial, we demonstrated how to:\n\n1. Load and prepare filter bank motor imagery data using MOABB\n2. Create a TensorCSPNet model for multi-frequency EEG classification\n3. Train and evaluate the model using Braindecode's EEGClassifier\n4. Visualize training history and confusion matrices\n\nTensorCSPNet leverages the geometry of SPD matrices to learn\ndiscriminative spatial filters across multiple frequency bands,\nmaking it well-suited for motor imagery classification.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Cleanup\nimport matplotlib.pyplot as plt\nplt.close('all')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}